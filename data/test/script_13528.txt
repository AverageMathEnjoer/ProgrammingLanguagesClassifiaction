b'/*\n    SPDX-FileCopyrightText: 2015-2020 Milian Wolff <mail@milianw.de>\n\n    SPDX-License-Identifier: LGPL-2.1-or-later\n*/\n\n#include "parser.h"\n\n#include <KLocalizedString>\n#include <ThreadWeaver/ThreadWeaver>\n\n#include <QDebug>\n#include <QElapsedTimer>\n#include <QThread>\n\n#include "analyze/accumulatedtracedata.h"\n\n#include <future>\n#include <tuple>\n#include <utility>\n#include <vector>\n\n#define TSL_NO_EXCEPTIONS 1\n#include <tsl/robin_map.h>\n#include <tsl/robin_set.h>\n\n#include <boost/functional/hash/hash.hpp>\n\nnamespace std {\ntemplate <>\nstruct hash<std::pair<Symbol, Symbol>>\n{\n    std::size_t operator()(const std::pair<Symbol, Symbol>& pair) const\n    {\n        return boost::hash_value(std::tie(pair.first.functionId.index, pair.first.moduleId.index,\n                                          pair.second.functionId.index, pair.second.moduleId.index));\n    }\n};\n}\n\nusing namespace std;\n\nnamespace {\nSymbol symbol(const Frame& frame, ModuleIndex moduleIndex)\n{\n    return {frame.functionIndex, moduleIndex};\n}\n\nSymbol symbol(const InstructionPointer& ip)\n{\n    return symbol(ip.frame, ip.moduleIndex);\n}\n\nstruct Location\n{\n    Symbol symbol;\n    FileLine fileLine;\n};\nLocation frameLocation(const Frame& frame, ModuleIndex moduleIndex)\n{\n    return {symbol(frame, moduleIndex), {frame.fileIndex, frame.line}};\n}\n\nLocation location(const InstructionPointer& ip)\n{\n    return frameLocation(ip.frame, ip.moduleIndex);\n}\n\nstruct ChartMergeData\n{\n    IpIndex ip;\n    qint64 consumed;\n    qint64 allocations;\n    qint64 temporary;\n    bool operator<(const IpIndex rhs) const\n    {\n        return ip < rhs;\n    }\n};\n\nconst uint64_t MAX_CHART_DATAPOINTS = 500; // TODO: make this configurable via the GUI\n\nQVector<Suppression> toQt(const std::vector<Suppression>& suppressions)\n{\n    QVector<Suppression> ret(suppressions.size());\n    std::copy(suppressions.begin(), suppressions.end(), ret.begin());\n    return ret;\n}\n}\n\nstruct ParserData final : public AccumulatedTraceData\n{\n    using TimestampCallback = std::function<void(const ParserData& data)>;\n    ParserData(TimestampCallback timestampCallback)\n        : timestampCallback(std::move(timestampCallback))\n    {\n    }\n\n    void prepareBuildCharts(const std::shared_ptr<const ResultData>& resultData)\n    {\n        if (diffMode) {\n            return;\n        }\n        consumedChartData.resultData = resultData;\n        consumedChartData.rows.reserve(MAX_CHART_DATAPOINTS);\n        allocationsChartData.resultData = resultData;\n        allocationsChartData.rows.reserve(MAX_CHART_DATAPOINTS);\n        temporaryChartData.resultData = resultData;\n        temporaryChartData.rows.reserve(MAX_CHART_DATAPOINTS);\n        // start off with null data at the origin\n        lastTimeStamp = filterParameters.minTime;\n        ChartRows origin;\n        origin.timeStamp = lastTimeStamp;\n        consumedChartData.rows.push_back(origin);\n        allocationsChartData.rows.push_back(origin);\n        temporaryChartData.rows.push_back(origin);\n        // index 0 indicates the total row\n        consumedChartData.labels[0] = {};\n        allocationsChartData.labels[0] = {};\n        temporaryChartData.labels[0] = {};\n\n        buildCharts = true;\n        maxConsumedSinceLastTimeStamp = 0;\n        vector<ChartMergeData> merged;\n        merged.reserve(instructionPointers.size());\n        // merge the allocation cost by instruction pointer\n        // TODO: traverse the merged call stack up until the first fork\n        for (const auto& alloc : allocations) {\n            const auto ip = findTrace(alloc.traceIndex).ipIndex;\n            auto it = lower_bound(merged.begin(), merged.end(), ip);\n            if (it == merged.end() || it->ip != ip) {\n                it = merged.insert(it, {ip, 0, 0, 0});\n            }\n            it->consumed += alloc.peak; // we want to track the top peaks in the chart\n            it->allocations += alloc.allocations;\n            it->temporary += alloc.temporary;\n        }\n        // find the top hot spots for the individual data members and remember their\n        // IP and store the label\n        tsl::robin_map<IpIndex, LabelIds> ipToLabelIds;\n        auto findTopChartEntries = [&](qint64 ChartMergeData::*member, int LabelIds::*label, ChartData* data) {\n            sort(merged.begin(), merged.end(), [=](const ChartMergeData& left, const ChartMergeData& right) {\n                return std::abs(left.*member) > std::abs(right.*member);\n            });\n            for (size_t i = 0; i < min(size_t(ChartRows::MAX_NUM_COST - 2), merged.size()); ++i) {\n                const auto& alloc = merged[i];\n                if (!(alloc.*member)) {\n                    break;\n                }\n                (ipToLabelIds[alloc.ip].*label) = i + 1;\n                data->labels[i + 1] = symbol(findIp(alloc.ip));\n                Q_ASSERT(data->labels.size() < ChartRows::MAX_NUM_COST);\n            }\n        };\n        ipToLabelIds.reserve(3 * ChartRows::MAX_NUM_COST);\n        findTopChartEntries(&ChartMergeData::consumed, &LabelIds::consumed, &consumedChartData);\n        findTopChartEntries(&ChartMergeData::allocations, &LabelIds::allocations, &allocationsChartData);\n        findTopChartEntries(&ChartMergeData::temporary, &LabelIds::temporary, &temporaryChartData);\n\n        // now iterate the allocations once to build the list of allocations\n        // we need to look at when we are building the charts in handleTimeStamp\n        // instead of doing this lookup every time we are handling a time stamp\n        for (uint32_t i = 0, c = allocations.size(); i < c; ++i) {\n            const auto ip = findTrace(allocations[i].traceIndex).ipIndex;\n            auto it = ipToLabelIds.find(ip);\n            if (it == ipToLabelIds.end())\n                continue;\n            auto ids = it->second;\n            ids.allocationIndex.index = i;\n            labelIds.push_back(ids);\n        }\n    }\n\n    void handleTimeStamp(int64_t /*oldStamp*/, int64_t newStamp, bool isFinalTimeStamp, ParsePass pass) override\n    {\n        if (timestampCallback) {\n            timestampCallback(*this);\n        }\n        if (pass == ParsePass::FirstPass) {\n            return;\n        }\n        if (!buildCharts || diffMode) {\n            return;\n        }\n        maxConsumedSinceLastTimeStamp = max(maxConsumedSinceLastTimeStamp, totalCost.leaked);\n        const auto timeSpan = (filterParameters.maxTime - filterParameters.minTime);\n        const int64_t diffBetweenTimeStamps = timeSpan / MAX_CHART_DATAPOINTS;\n        if (!isFinalTimeStamp && (newStamp - lastTimeStamp) < diffBetweenTimeStamps) {\n            return;\n        }\n        const auto nowConsumed = maxConsumedSinceLastTimeStamp;\n        maxConsumedSinceLastTimeStamp = 0;\n        lastTimeStamp = newStamp;\n\n        // create the rows\n        auto createRow = [newStamp](int64_t totalCost) {\n            ChartRows row;\n            row.timeStamp = newStamp;\n            row.cost[0] = totalCost;\n            return row;\n        };\n        auto consumed = createRow(nowConsumed);\n        auto allocs = createRow(totalCost.allocations);\n        auto temporary = createRow(totalCost.temporary);\n\n        // if the cost is non-zero and the ip corresponds to a hotspot function\n        // selected in the labels, we add the cost to the rows column\n        auto addDataToRow = [](int64_t cost, int labelId, ChartRows* rows) {\n            if (!cost || labelId == -1) {\n                return;\n            }\n            rows->cost[labelId] += cost;\n        };\n        for (const auto& ids : labelIds) {\n            const auto alloc = allocations[ids.allocationIndex.index];\n            addDataToRow(alloc.leaked, ids.consumed, &consumed);\n            addDataToRow(alloc.allocations, ids.allocations, &allocs);\n            addDataToRow(alloc.temporary, ids.temporary, &temporary);\n        }\n        // add the rows for this time stamp\n        consumedChartData.rows << consumed;\n        allocationsChartData.rows << allocs;\n        temporaryChartData.rows << temporary;\n    }\n\n    void handleAllocation(const AllocationInfo& info, const AllocationInfoIndex index) override\n    {\n        maxConsumedSinceLastTimeStamp = max(maxConsumedSinceLastTimeStamp, totalCost.leaked);\n\n        if (index.index == allocationInfoCounter.size()) {\n            allocationInfoCounter.push_back({info, 1});\n        } else {\n            ++allocationInfoCounter[index.index].allocations;\n        }\n    }\n\n    void handleDebuggee(const char* command) override\n    {\n        debuggee = command;\n    }\n\n    void clearForReparse()\n    {\n        // data moved to size histogram\n        {\n            // we have to reset the allocation count\n            for (auto& info : allocationInfoCounter)\n                info.allocations = 0;\n            // and restore the order to allow fast direct access\n            std::sort(allocationInfoCounter.begin(), allocationInfoCounter.end(),\n                      [](const ParserData::CountedAllocationInfo& lhs, const ParserData::CountedAllocationInfo& rhs) {\n                          return lhs.info.allocationIndex < rhs.info.allocationIndex;\n                      });\n        }\n        // data moved to chart models\n        consumedChartData = {};\n        allocationsChartData = {};\n        temporaryChartData = {};\n        labelIds.clear();\n        maxConsumedSinceLastTimeStamp = 0;\n        lastTimeStamp = 0;\n        buildCharts = false;\n    }\n\n    string debuggee;\n\n    struct CountedAllocationInfo\n    {\n        AllocationInfo info;\n        int64_t allocations;\n        bool operator<(const CountedAllocationInfo& rhs) const\n        {\n            return tie(info.size, allocations) < tie(rhs.info.size, rhs.allocations);\n        }\n    };\n    /// counts how often a given allocation info is encountered based on its index\n    /// used to build the size histogram\n    vector<CountedAllocationInfo> allocationInfoCounter;\n\n    ChartData consumedChartData;\n    ChartData allocationsChartData;\n    ChartData temporaryChartData;\n    // here we store the indices into ChartRows::cost for those IpIndices that\n    // are within the top hotspots. This way, we can do one hash lookup in the\n    // handleTimeStamp function instead of three when we\'d store this data\n    // in a per-ChartData hash.\n    struct LabelIds\n    {\n        AllocationIndex allocationIndex;\n        int consumed = -1;\n        int allocations = -1;\n        int temporary = -1;\n    };\n    vector<LabelIds> labelIds;\n    int64_t maxConsumedSinceLastTimeStamp = 0;\n    int64_t lastTimeStamp = 0;\n\n    bool buildCharts = false;\n    bool diffMode = false;\n\n    TimestampCallback timestampCallback;\n    QElapsedTimer parseTimer;\n\n    QVector<QString> qtStrings;\n};\n\nnamespace {\nvoid setParents(QVector<RowData>& children, const RowData* parent)\n{\n    children.squeeze();\n    for (auto& row : children) {\n        row.parent = parent;\n        setParents(row.children, &row);\n    }\n}\n\nvoid addCallerCalleeEvent(const Location& location, const AllocationData& cost, tsl::robin_set<Symbol>* recursionGuard,\n                          CallerCalleeResults* callerCalleeResult)\n{\n    const auto isLeaf = recursionGuard->empty();\n    if (!recursionGuard->insert(location.symbol).second) {\n        return;\n    }\n\n    auto& entry = callerCalleeResult->entries[location.symbol];\n    auto& locationCost = entry.sourceMap[location.fileLine];\n\n    locationCost.inclusiveCost += cost;\n    if (isLeaf) {\n        // increment self cost for leaf\n        locationCost.selfCost += cost;\n    }\n}\n\nstd::pair<TreeData, CallerCalleeResults> mergeAllocations(Parser* parser, const ParserData& data,\n                                                          std::shared_ptr<const ResultData> resultData)\n{\n    CallerCalleeResults callerCalleeResults;\n    TreeData topRows;\n    tsl::robin_set<TraceIndex> traceRecursionGuard;\n    traceRecursionGuard.reserve(128);\n    tsl::robin_set<Symbol> symbolRecursionGuard;\n    symbolRecursionGuard.reserve(128);\n    auto addRow = [&symbolRecursionGuard, &callerCalleeResults](QVector<RowData>* rows, const Location& location,\n                                                                const Allocation& cost) -> QVector<RowData>* {\n        auto it = lower_bound(rows->begin(), rows->end(), location.symbol);\n        if (it != rows->end() && it->symbol == location.symbol) {\n            it->cost += cost;\n        } else {\n            it = rows->insert(it, {cost, location.symbol, nullptr, {}});\n        }\n        addCallerCalleeEvent(location, cost, &symbolRecursionGuard, &callerCalleeResults);\n        return &it->children;\n    };\n    const auto allocationCount = data.allocations.size();\n    const auto onePercent = std::max<size_t>(1, allocationCount / 100);\n    auto progress = 0;\n    // merge allocations, leave parent pointers invalid (their location may change)\n    for (const auto& allocation : data.allocations) {\n        auto traceIndex = allocation.traceIndex;\n        auto rows = &topRows.rows;\n        traceRecursionGuard.clear();\n        traceRecursionGuard.insert(traceIndex);\n        symbolRecursionGuard.clear();\n        bool first = true;\n        while (traceIndex || first) {\n            first = false;\n            const auto& trace = data.findTrace(traceIndex);\n            const auto& ip = data.findIp(trace.ipIndex);\n            rows = addRow(rows, location(ip), allocation);\n            for (const auto& inlined : ip.inlined) {\n                const auto& inlinedLocation = frameLocation(inlined, ip.moduleIndex);\n                rows = addRow(rows, inlinedLocation, allocation);\n            }\n            if (data.isStopIndex(ip.frame.functionIndex)) {\n                break;\n            }\n            traceIndex = trace.parentIndex;\n            if (!traceRecursionGuard.insert(traceIndex).second) {\n                qWarning() << "Trace recursion detected - corrupt data file?";\n                break;\n            }\n        }\n        ++progress;\n        if ((progress % onePercent) == 0) {\n            const int percent = progress * 100 / allocationCount;\n            emit parser->progressMessageAvailable(i18n("merging allocations... %1%", percent));\n        }\n    }\n    // now set the parents, the data is constant from here on\n    setParents(topRows.rows, nullptr);\n\n    topRows.resultData = std::move(resultData);\n    return {topRows, callerCalleeResults};\n}\n\nRowData* findBySymbol(Symbol symbol, QVector<RowData>* data)\n{\n    auto it = std::find_if(data->begin(), data->end(), [symbol](const RowData& row) { return row.symbol == symbol; });\n    return it == data->end() ? nullptr : &(*it);\n}\n\nAllocationData buildTopDown(const QVector<RowData>& bottomUpData, QVector<RowData>* topDownData)\n{\n    AllocationData totalCost;\n    for (const auto& row : bottomUpData) {\n        // recurse and find the cost attributed to children\n        const auto childCost = buildTopDown(row.children, topDownData);\n        if (childCost != row.cost) {\n            // this row is (partially) a leaf\n            const auto cost = row.cost - childCost;\n\n            // bubble up the parent chain to build a top-down tree\n            auto node = &row;\n            auto stack = topDownData;\n            while (node) {\n                auto data = findBySymbol(node->symbol, stack);\n                if (!data) {\n                    // create an empty top-down item for this bottom-up node\n                    *stack << RowData {{}, node->symbol, nullptr, {}};\n                    data = &stack->back();\n                }\n                // always use the leaf node\'s cost and propagate that one up the chain\n                // otherwise we\'d count the cost of some nodes multiple times\n                data->cost += cost;\n                stack = &data->children;\n                node = node->parent;\n            }\n        }\n        totalCost += row.cost;\n    }\n    return totalCost;\n}\n\nTreeData toTopDownData(const TreeData& bottomUpData)\n{\n    TreeData topRows;\n    topRows.resultData = bottomUpData.resultData;\n    buildTopDown(bottomUpData.rows, &topRows.rows);\n    // now set the parents, the data is constant from here on\n    setParents(topRows.rows, nullptr);\n    return topRows;\n}\n\nstruct ReusableGuardBuffer\n{\n    ReusableGuardBuffer()\n    {\n        recursionGuard.reserve(128);\n        callerCalleeRecursionGuard.reserve(128);\n    }\n\n    void reset()\n    {\n        recursionGuard.clear();\n        callerCalleeRecursionGuard.clear();\n    }\n\n    tsl::robin_set<Symbol> recursionGuard;\n    tsl::robin_set<std::pair<Symbol, Symbol>> callerCalleeRecursionGuard;\n};\n\nAllocationData buildCallerCallee(const QVector<RowData>& bottomUpData, CallerCalleeResults* callerCalleeResults,\n                                 ReusableGuardBuffer* guardBuffer)\n{\n    AllocationData totalCost;\n    for (const auto& row : bottomUpData) {\n        // recurse to find a leaf\n        const auto childCost = buildCallerCallee(row.children, callerCalleeResults, guardBuffer);\n        if (childCost != row.cost) {\n            // this row is (partially) a leaf\n            const auto cost = row.cost - childCost;\n\n            // leaf node found, bubble up the parent chain to add cost for all frames\n            // to the caller/callee data. this is done top-down since we must not count\n            // symbols more than once in the caller-callee data\n            guardBuffer->reset();\n            auto& recursionGuard = guardBuffer->recursionGuard;\n            auto& callerCalleeRecursionGuard = guardBuffer->callerCalleeRecursionGuard;\n\n            auto node = &row;\n\n            Symbol lastSymbol;\n            CallerCalleeEntry* lastEntry = nullptr;\n\n            while (node) {\n                const auto symbol = node->symbol;\n                // aggregate caller-callee data\n                auto& entry = callerCalleeResults->entries[symbol];\n                if (recursionGuard.insert(symbol).second) {\n                    // only increment inclusive cost once for a given stack\n                    entry.inclusiveCost += cost;\n                }\n                if (!node->parent) {\n                    // always increment the self cost\n                    entry.selfCost += cost;\n                }\n                // add current entry as callee to last entry\n                // and last entry as caller to current entry\n                if (lastEntry) {\n                    if (callerCalleeRecursionGuard.insert({symbol, lastSymbol}).second) {\n                        lastEntry->callees[symbol] += cost;\n                        entry.callers[lastSymbol] += cost;\n                    }\n                }\n\n                node = node->parent;\n                lastSymbol = symbol;\n                lastEntry = &entry;\n            }\n        }\n        totalCost += row.cost;\n    }\n    return totalCost;\n}\n\nCallerCalleeResults toCallerCalleeData(const TreeData& bottomUpData, const CallerCalleeResults& results, bool diffMode)\n{\n    // copy the source map and continue from there\n    auto callerCalleeResults = results;\n    ReusableGuardBuffer guardBuffer;\n    buildCallerCallee(bottomUpData.rows, &callerCalleeResults, &guardBuffer);\n\n    if (diffMode) {\n        // remove rows without cost\n        for (auto it = callerCalleeResults.entries.begin(); it != callerCalleeResults.entries.end();) {\n            if (it->inclusiveCost == AllocationData() && it->selfCost == AllocationData()) {\n                it = callerCalleeResults.entries.erase(it);\n            } else {\n                ++it;\n            }\n        }\n    }\n\n    callerCalleeResults.resultData = bottomUpData.resultData;\n    return callerCalleeResults;\n}\n\nstruct MergedHistogramColumnData\n{\n    Symbol symbol;\n    int64_t allocations;\n    int64_t totalAllocated;\n    bool operator<(const Symbol& rhs) const\n    {\n        return symbol < rhs;\n    }\n};\n\nHistogramData buildSizeHistogram(ParserData& data, std::shared_ptr<const ResultData> resultData)\n{\n    HistogramData ret;\n    if (data.allocationInfoCounter.empty()) {\n        return ret;\n    }\n    sort(data.allocationInfoCounter.begin(), data.allocationInfoCounter.end());\n    const auto totalLabel = i18n("total");\n    HistogramRow row;\n    const pair<uint64_t, QString> buckets[] = {{8, i18n("0B to 8B")},\n                                               {16, i18n("9B to 16B")},\n                                               {32, i18n("17B to 32B")},\n                                               {64, i18n("33B to 64B")},\n                                               {128, i18n("65B to 128B")},\n                                               {256, i18n("129B to 256B")},\n                                               {512, i18n("257B to 512B")},\n                                               {1024, i18n("512B to 1KB")},\n                                               {numeric_limits<uint64_t>::max(), i18n("more than 1KB")}};\n    uint bucketIndex = 0;\n    row.size = buckets[bucketIndex].first;\n    row.sizeLabel = buckets[bucketIndex].second;\n    vector<MergedHistogramColumnData> columnData;\n    columnData.reserve(128);\n    auto insertColumns = [&]() {\n        sort(columnData.begin(), columnData.end(),\n             [](const MergedHistogramColumnData& lhs, const MergedHistogramColumnData& rhs) {\n                 return std::tie(lhs.allocations, lhs.totalAllocated) > std::tie(rhs.allocations, rhs.totalAllocated);\n             });\n        // -1 to account for total row\n        for (size_t i = 0; i < min(columnData.size(), size_t(HistogramRow::NUM_COLUMNS - 1)); ++i) {\n            const auto& column = columnData[i];\n            row.columns[i + 1] = {column.allocations, column.totalAllocated, column.symbol};\n        }\n    };\n    for (const auto& info : data.allocationInfoCounter) {\n        if (info.info.size > row.size) {\n            insertColumns();\n            columnData.clear();\n            ret.rows << row;\n            ++bucketIndex;\n            row.size = buckets[bucketIndex].first;\n            row.sizeLabel = buckets[bucketIndex].second;\n            row.columns[0] = {info.allocations, static_cast<qint64>(info.info.size * info.allocations), {}};\n        } else {\n            auto& column = row.columns[0];\n            column.allocations += info.allocations;\n            column.totalAllocated += info.info.size * info.allocations;\n        }\n        const auto& allocation = data.allocations[info.info.allocationIndex.index];\n        const auto& ipIndex = data.findTrace(allocation.traceIndex).ipIndex;\n        const auto& ip = data.findIp(ipIndex);\n        const auto& sym = symbol(ip);\n        auto it = lower_bound(columnData.begin(), columnData.end(), sym);\n        if (it == columnData.end() || it->symbol != sym) {\n            columnData.insert(it, {sym, info.allocations, static_cast<qint64>(info.info.size * info.allocations)});\n        } else {\n            it->allocations += info.allocations;\n            it->totalAllocated += static_cast<qint64>(info.info.size * info.allocations);\n        }\n    }\n    insertColumns();\n    ret.rows << row;\n    ret.resultData = std::move(resultData);\n    return ret;\n}\n}\n\nParser::Parser(QObject* parent)\n    : QObject(parent)\n{\n    qRegisterMetaType<SummaryData>();\n}\n\nParser::~Parser() = default;\n\nbool Parser::isFiltered() const\n{\n    if (!m_data)\n        return false;\n    return m_data->filterParameters.isFilteredByTime(m_data->totalTime);\n}\n\nvoid Parser::parse(const QString& path, const QString& diffBase, const FilterParameters& filterParameters,\n                   StopAfter stopAfter)\n{\n    parseImpl(path, diffBase, filterParameters, stopAfter);\n}\n\nvoid Parser::parseImpl(const QString& path, const QString& diffBase, const FilterParameters& filterParameters,\n                       StopAfter stopAfter)\n{\n    auto oldData = std::move(m_data);\n    using namespace ThreadWeaver;\n    stream() << make_job([this, oldData, path, diffBase, filterParameters, stopAfter]() {\n        const auto isReparsing = (path == m_path && oldData && diffBase.isEmpty());\n        auto parsingMsg = isReparsing ? i18n("reparsing data") : i18n("parsing data");\n\n        auto updateProgress = [this, parsingMsg, lastPassCompletion = 0.f](const ParserData& data) mutable {\n            auto passCompletion = 1.0 * data.parsingState.readCompressedByte / data.parsingState.fileSize;\n            if (std::abs(lastPassCompletion - passCompletion) < 0.001) {\n                // don\'t spam the progress bar\n                return;\n            }\n\n            lastPassCompletion = passCompletion;\n            const auto numPasses = data.diffMode ? 2 : 3;\n            auto totalCompletion = (data.parsingState.pass + passCompletion) / numPasses;\n            auto spentTime_ms = data.parseTimer.elapsed();\n            auto totalRemainingTime_ms = (spentTime_ms / totalCompletion) * (1.0 - totalCompletion);\n            auto message = i18n("%1 pass: %2/%3  spent: %4  remaining: %5", parsingMsg, data.parsingState.pass + 1,\n                                numPasses, Util::formatTime(spentTime_ms), Util::formatTime(totalRemainingTime_ms));\n\n            emit progressMessageAvailable(message);\n            emit progress(1000 * totalCompletion); // range is set as 0 to 1000 for fractional % bar display\n        };\n\n        const auto stdPath = path.toStdString();\n        auto data = isReparsing ? oldData : make_shared<ParserData>(updateProgress);\n        data->filterParameters = filterParameters;\n\n        emit progressMessageAvailable(parsingMsg);\n        data->parseTimer.start();\n\n        if (!diffBase.isEmpty()) {\n            ParserData diffData(nullptr); // currently we don\'t track the progress of diff parsing\n            auto readBase = async(launch::async, [&diffData, diffBase, isReparsing]() {\n                return diffData.read(diffBase.toStdString(), isReparsing);\n            });\n            if (!data->read(stdPath, isReparsing)) {\n                emit failedToOpen(path);\n                return;\n            }\n            if (!readBase.get()) {\n                emit failedToOpen(diffBase);\n                return;\n            }\n            data->diff(diffData);\n            data->diffMode = true;\n        } else {\n            if (!data->read(stdPath, isReparsing)) {\n                emit failedToOpen(path);\n                return;\n            }\n        }\n\n        if (!isReparsing) {\n            data->qtStrings.resize(data->strings.size());\n            std::transform(data->strings.begin(), data->strings.end(), data->qtStrings.begin(),\n                           [](const std::string& string) { return QString::fromStdString(string); });\n        }\n\n        data->applyLeakSuppressions();\n\n        const auto resultData = std::make_shared<const ResultData>(data->totalCost, data->qtStrings);\n\n        emit summaryAvailable({QString::fromStdString(data->debuggee), data->totalCost, data->totalTime,\n                               data->filterParameters, data->peakTime, data->peakRSS * data->systemInfo.pageSize,\n                               data->systemInfo.pages * data->systemInfo.pageSize, data->fromAttached,\n                               data->totalLeakedSuppressed, toQt(data->suppressions)});\n\n        if (stopAfter == StopAfter::Summary) {\n            emit finished();\n            return;\n        }\n\n        emit progressMessageAvailable(i18n("merging allocations..."));\n        // merge allocations before modifying the data again\n        const auto mergedAllocations = mergeAllocations(this, *data, resultData);\n        emit bottomUpDataAvailable(mergedAllocations.first);\n\n        if (stopAfter == StopAfter::BottomUp) {\n            emit finished();\n            return;\n        }\n\n        // also calculate the size histogram\n        emit progressMessageAvailable(i18n("building size histogram..."));\n        const auto sizeHistogram = buildSizeHistogram(*data, resultData);\n        emit sizeHistogramDataAvailable(sizeHistogram);\n        // now data can be modified again for the chart data evaluation\n\n        if (stopAfter == StopAfter::SizeHistogram) {\n            emit finished();\n            return;\n        }\n\n        emit progress(0);\n\n        const auto diffMode = data->diffMode;\n        emit progressMessageAvailable(i18n("building charts..."));\n        auto parallel = new Collection;\n        *parallel << make_job([this, mergedAllocations, resultData]() {\n            const auto topDownData = toTopDownData(mergedAllocations.first);\n            emit topDownDataAvailable(topDownData);\n        }) << make_job([this, mergedAllocations, diffMode]() {\n            emit callerCalleeDataAvailable(\n                toCallerCalleeData(mergedAllocations.first, mergedAllocations.second, diffMode));\n        });\n        if (!data->diffMode && stopAfter != StopAfter::TopDownAndCallerCallee) {\n            // only build charts when we are not diffing\n            *parallel << make_job([this, data, stdPath, isReparsing, resultData]() {\n                // this mutates data, and thus anything running in parallel must\n                // not access data\n                data->prepareBuildCharts(resultData);\n                data->read(stdPath, AccumulatedTraceData::ThirdPass, isReparsing);\n                emit consumedChartDataAvailable(data->consumedChartData);\n                emit allocationsChartDataAvailable(data->allocationsChartData);\n                emit temporaryChartDataAvailable(data->temporaryChartData);\n            });\n        }\n\n        emit progress(0);\n\n        auto sequential = new Sequence;\n        *sequential << parallel << make_job([this, data, path]() {\n            QMetaObject::invokeMethod(this, [this, data, path]() {\n                Q_ASSERT(QThread::currentThread() == thread());\n                m_data = data;\n                m_data->clearForReparse();\n                m_path = path;\n                emit finished();\n            });\n        });\n\n        stream() << sequential;\n    });\n}\n\nvoid Parser::reparse(const FilterParameters& parameters_)\n{\n    if (!m_data || m_data->diffMode)\n        return;\n\n    auto filterParameters = parameters_;\n    filterParameters.minTime = std::max(int64_t(0), filterParameters.minTime);\n    filterParameters.maxTime = std::min(m_data->totalTime, filterParameters.maxTime);\n\n    parseImpl(m_path, {}, filterParameters, StopAfter::Finished);\n}\n'