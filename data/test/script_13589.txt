b'{-# LANGUAGE RankNTypes, NamedFieldPuns, BangPatterns,\n             ExistentialQuantification, CPP, DeriveDataTypeable #-}\n{-# OPTIONS_GHC -Wall -fno-warn-name-shadowing -fno-warn-unused-do-bind #-}\n\n-- | This module exposes the internals of the @Par@ monad so that you\n-- can build your own scheduler or other extensions.  Do not use this\n-- module for purposes other than extending the @Par@ monad with new\n-- functionality.\n\nmodule Control.Monad.Par.Scheds.TraceInternal (\n   Trace(..), Sched(..), Par(..),\n   IVar(..), IVarContents(..),\n   sched,\n   runPar, runParIO, runParAsync,\n   -- runParAsyncHelper,\n   new, newFull, newFull_, get, put_, put,\n   pollIVar, yield, fixPar, FixParException (..)\n ) where\n\n#if MIN_VERSION_base(4,6,0)\nimport Prelude hiding (mapM, sequence, head,tail)\n#else\nimport Prelude hiding (mapM, sequence, head,tail,catch)\n#endif\n\nimport Control.Monad as M hiding (mapM, sequence, join)\nimport Data.IORef\nimport System.IO.Unsafe\n#if MIN_VERSION_base(4,9,0)\nimport GHC.IO.Unsafe (unsafeDupableInterleaveIO)\n#else\nimport System.IO.Unsafe (unsafeInterleaveIO)\n#endif\nimport Control.Concurrent hiding (yield)\nimport GHC.Conc (numCapabilities)\nimport Control.DeepSeq\nimport Control.Monad.Fix (MonadFix (mfix))\nimport Control.Exception (Exception, throwIO, BlockedIndefinitelyOnMVar (..),\n                          catch)\nimport Data.Typeable (Typeable)\n-- import Text.Printf\n\n#if !MIN_VERSION_base(4,8,0)\nimport Control.Applicative\n#endif\n\n#if __GLASGOW_HASKELL__ <= 700\nimport GHC.Conc (forkOnIO)\nforkOn = forkOnIO\n#endif\n\n\n-- ---------------------------------------------------------------------------\n\ndata Trace = forall a . Get (IVar a) (a -> Trace)\n           | forall a . Put (IVar a) a Trace\n           | forall a . New (IVarContents a) (IVar a -> Trace)\n           | Fork Trace Trace\n           | Done\n           | Yield Trace\n           | forall a . LiftIO (IO a) (a -> Trace)\n\n-- | The main scheduler loop.\nsched :: Bool -> Sched -> Trace -> IO ()\nsched _doSync queue t = loop t\n where\n  loop t = case t of\n    New a f -> do\n      r <- newIORef a\n      loop (f (IVar r))\n    Get (IVar v) c -> do\n      e <- readIORef v\n      case e of\n         Full a -> loop (c a)\n         _other -> do\n           r <- atomicModifyIORef v $ \\e -> case e of\n                        Empty    -> (Blocked [c], reschedule queue)\n                        Full a   -> (Full a,      loop (c a))\n                        Blocked cs -> (Blocked (c:cs), reschedule queue)\n           r\n    Put (IVar v) a t  -> do\n      cs <- atomicModifyIORef v $ \\e -> case e of\n               Empty    -> (Full a, [])\n               Full _   -> error "multiple put"\n               Blocked cs -> (Full a, cs)\n      mapM_ (pushWork queue. ($a)) cs\n      loop t\n    Fork child parent -> do\n         pushWork queue child\n         loop parent\n    Done ->\n         if _doSync\n         then reschedule queue\n-- We could fork an extra thread here to keep numCapabilities workers\n-- even when the main thread returns to the runPar caller...\n         else do putStrLn " [par] Forking replacement thread..\\n"\n                 forkIO (reschedule queue); return ()\n-- But even if we don\'t we are not orphaning any work in this\n-- threads work-queue because it can be stolen by other threads.\n--       else return ()\n\n    Yield parent -> do\n        -- Go to the end of the worklist:\n        let Sched { workpool } = queue\n        -- TODO: Perhaps consider Data.Seq here.\n        -- This would also be a chance to steal and work from opposite ends of the queue.\n        atomicModifyIORef workpool $ \\ts -> (ts++[parent], ())\n        reschedule queue\n    LiftIO io c -> do\n        r <- io\n        loop (c r)\n\ndata FixParException = FixParException deriving (Show, Typeable)\ninstance Exception FixParException\n\n-- | Process the next item on the work queue or, failing that, go into\n--   work-stealing mode.\nreschedule :: Sched -> IO ()\nreschedule queue@Sched{ workpool } = do\n  e <- atomicModifyIORef workpool $ \\ts ->\n         case ts of\n           []      -> ([], Nothing)\n           (t:ts\') -> (ts\', Just t)\n  case e of\n    Nothing -> steal queue\n    Just t  -> sched True queue t\n\n\n-- RRN: Note -- NOT doing random work stealing breaks the traditional\n-- Cilk time/space bounds if one is running strictly nested (series\n-- parallel) programs.\n\n-- | Attempt to steal work or, failing that, give up and go idle.\nsteal :: Sched -> IO ()\nsteal q@Sched{ idle, scheds, no=my_no } = do\n  -- printf "cpu %d stealing\\n" my_no\n  go scheds\n  where\n    go [] = do m <- newEmptyMVar\n               r <- atomicModifyIORef idle $ \\is -> (m:is, is)\n               if length r == numCapabilities - 1\n                  then do\n                     -- printf "cpu %d initiating shutdown\\n" my_no\n                     mapM_ (\\m -> putMVar m True) r\n                  else do\n                    done <- takeMVar m\n                    if done\n                       then do\n                         -- printf "cpu %d shutting down\\n" my_no\n                         return ()\n                       else do\n                         -- printf "cpu %d woken up\\n" my_no\n                         go scheds\n    go (x:xs)\n      | no x == my_no = go xs\n      | otherwise     = do\n         r <- atomicModifyIORef (workpool x) $ \\ ts ->\n                 case ts of\n                    []     -> ([], Nothing)\n                    (x:xs) -> (xs, Just x)\n         case r of\n           Just t  -> do\n              -- printf "cpu %d got work from cpu %d\\n" my_no (no x)\n              sched True q t\n           Nothing -> go xs\n\n-- | If any worker is idle, wake one up and give it work to do.\npushWork :: Sched -> Trace -> IO ()\npushWork Sched { workpool, idle } t = do\n  atomicModifyIORef workpool $ \\ts -> (t:ts, ())\n  idles <- readIORef idle\n  when (not (null idles)) $ do\n    r <- atomicModifyIORef idle (\\is -> case is of\n                                          [] -> ([], return ())\n                                          (i:is) -> (is, putMVar i False))\n    r -- wake one up\n\ndata Sched = Sched\n    { no       :: {-# UNPACK #-} !Int,\n      workpool :: IORef [Trace],\n      idle     :: IORef [MVar Bool],\n      scheds   :: [Sched] -- Global list of all per-thread workers.\n    }\n--  deriving Show\n\nnewtype Par a = Par {\n    runCont :: (a -> Trace) -> Trace\n}\n\ninstance Functor Par where\n    fmap f m = Par $ \\c -> runCont m (c . f)\n\ninstance Monad Par where\n    return = pure\n    m >>= k  = Par $ \\c -> runCont m $ \\a -> runCont (k a) c\n\ninstance Applicative Par where\n   (<*>) = ap\n   pure a = Par ($ a)\n\ninstance MonadFix Par where\n   mfix = fixPar\n\n-- | Take the monadic fixpoint of a \'Par\' computation. This is\n-- the definition of \'mfix\' for \'Par\'. Throws \'FixParException\'\n-- if the result is demanded strictly within the computation.\nfixPar :: (a -> Par a) -> Par a\n-- We do this IO-style, rather than ST-style, in order to get a\n-- consistent exception type. Using the ST-style mfix, a strict\n-- argument could lead us to *either* a <<loop>> exception *or*\n-- (if the wrong sort of computation gets re-run) a "multiple-put"\n-- error.\nfixPar f = Par $ \\ c ->\n  LiftIO (do\n    mv <- newEmptyMVar\n    ans <- unsafeDupableInterleaveIO (readMVar mv\n             `catch` \\ ~BlockedIndefinitelyOnMVar -> throwIO FixParException)\n    case f ans of\n      Par q -> pure $ q $ \\a -> LiftIO (putMVar mv a) (\\ ~() -> c a)) id\n\n#if !MIN_VERSION_base(4,9,0)\nunsafeDupableInterleaveIO :: IO a -> IO a\nunsafeDupableInterleaveIO = unsafeInterleaveIO\n#endif\n\nnewtype IVar a = IVar (IORef (IVarContents a))\n-- data IVar a = IVar (IORef (IVarContents a))\n\n-- | Equality for IVars is physical equality, as with other reference types.\ninstance Eq (IVar a) where\n  (IVar r1) == (IVar r2) = r1 == r2\n\ninstance NFData (IVar a) where\n  rnf !_ = ()\n\n\n-- From outside the Par computation we can peek.  But this is nondeterministic.\npollIVar :: IVar a -> IO (Maybe a)\npollIVar (IVar ref) =\n  do contents <- readIORef ref\n     case contents of\n       Full x -> return (Just x)\n       _      -> return (Nothing)\n\n\ndata IVarContents a = Full a | Empty | Blocked [a -> Trace]\n\n\n{-# INLINE runPar_internal #-}\nrunPar_internal :: Bool -> Par a -> IO a\nrunPar_internal _doSync x = do\n   workpools <- replicateM numCapabilities $ newIORef []\n   idle <- newIORef []\n   let states = [ Sched { no=x, workpool=wp, idle, scheds=states }\n                | (x,wp) <- zip [0..] workpools ]\n\n#if __GLASGOW_HASKELL__ >= 701 /* 20110301 */\n    --\n    -- We create a thread on each CPU with forkOn.  The CPU on which\n    -- the current thread is running will host the main thread; the\n    -- other CPUs will host worker threads.\n    --\n    -- Note: GHC 7.1.20110301 is required for this to work, because that\n    -- is when threadCapability was added.\n    --\n   (main_cpu, _) <- threadCapability =<< myThreadId\n#else\n    --\n    -- Lacking threadCapability, we always pick CPU #0 to run the main\n    -- thread.  If the current thread is not running on CPU #0, this\n    -- will require some data to be shipped over the memory bus, and\n    -- hence will be slightly slower than the version above.\n    --\n   let main_cpu = 0\n#endif\n\n   m <- newEmptyMVar\n   forM_ (zip [0..] states) $ \\(cpu,state) ->\n        forkOn cpu $\n          if (cpu /= main_cpu)\n             then reschedule state\n             else do\n                  rref <- newIORef Empty\n                  sched _doSync state $ runCont (x >>= put_ (IVar rref)) (const Done)\n                  readIORef rref >>= putMVar m\n\n   r <- takeMVar m\n   case r of\n     Full a -> return a\n     _ -> error "no result"\n\n\n-- | Run a parallel, deterministic computation and return its result.\n-- \n--   Note: you must NOT return an IVar in the output of the parallel\n--   computation.  This is unfortunately not enforced, as it is with\n--   `runST` or with newer libraries that export a Par monad, such as\n--   `lvish`.\nrunPar :: Par a -> a\nrunPar = unsafePerformIO . runPar_internal True\n\n-- | A version that avoids an internal `unsafePerformIO` for calling\n--   contexts that are already in the `IO` monad.\n--\n--   Returning any value containing IVar is still disallowed, as it\n--   can compromise type safety.\nrunParIO :: Par a -> IO a\nrunParIO = runPar_internal True\n\n-- | An asynchronous version in which the main thread of control in a\n-- Par computation can return while forked computations still run in\n-- the background.\nrunParAsync :: Par a -> a\nrunParAsync = unsafePerformIO . runPar_internal False\n\n-- -----------------------------------------------------------------------------\n\n-- | Creates a new @IVar@\nnew :: Par (IVar a)\nnew  = Par $ New Empty\n\n-- | Creates a new @IVar@ that contains a value\nnewFull :: NFData a => a -> Par (IVar a)\n-- What are we doing here? We\'re manually raising the arity\n-- of newFull from 2 to 3, which seems like it\'s probably what\n-- we want most of the time. Notably, fmapping over the result\n-- gives really awful-looking Core if we don\'t do this.\n-- Regardless, I think we logically want to force the\n-- value when it\'s installed in the IVar rather than\n-- when we create the action to install it in the IVar.\nnewFull x = Par $ \\c -> x `deepseq` New (Full x) c\n\n-- | Creates a new @IVar@ that contains a value (head-strict only)\nnewFull_ :: a -> Par (IVar a)\nnewFull_ !x = Par $ New (Full x)\n\n-- | Read the value in an @IVar@.  The \'get\' operation can only return when the\n-- value has been written by a prior or parallel @put@ to the same\n-- @IVar@.\nget :: IVar a -> Par a\nget v = Par $ \\c -> Get v c\n\n-- | Like \'put\', but only head-strict rather than fully-strict.\nput_ :: IVar a -> a -> Par ()\nput_ v !a = Par $ \\c -> Put v a (c ())\n\n-- | Put a value into an @IVar@.  Multiple \'put\'s to the same @IVar@\n-- are not allowed, and result in a runtime error.\n--\n-- \'put\' fully evaluates its argument, which therefore must be an\n-- instance of \'NFData\'.  The idea is that this forces the work to\n-- happen when we expect it, rather than being passed to the consumer\n-- of the @IVar@ and performed later, which often results in less\n-- parallelism than expected.\n--\n-- Sometimes partial strictness is more appropriate: see \'put_\'.\n--\nput :: NFData a => IVar a -> a -> Par ()\n-- Manually raise the arity, which seems likely to be what\n-- we want most of the time. We really want to force the\n-- value when it\'s installed in the IVar, not when we\n-- create the Par action to install it in the IVar.\nput v a = Par $ \\c -> a `deepseq` Put v a (c ())\n\n-- | Allows other parallel computations to progress.  (should not be\n-- necessary in most cases).\nyield :: Par ()\nyield = Par $ \\c -> Yield (c ())\n'