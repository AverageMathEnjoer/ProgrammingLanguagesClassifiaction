b'# Unexported, low-level function for fitting negative binomial GLMs\n#\n# Users typically call \\code{\\link{nbinomWaldTest}} or \\code{\\link{nbinomLRT}}\n# which calls this function to perform fitting.  These functions return\n# a \\code{\\link{DESeqDataSet}} object with the appropriate columns\n# added.  This function returns results as a list.\n#\n# object a DESeqDataSet\n# modelMatrix the design matrix\n# modelFormula a formula specifying how to construct the design matrix\n# alpha_hat the dispersion parameter estimates\n# lambda the \'ridge\' term added for the penalized GLM on the log2 scale\n# renameCols whether to give columns variable_B_vs_A style names\n# betaTol control parameter: stop when the following is satisfied:\n#   abs(dev - dev_old)/(abs(dev) + 0.1) < betaTol\n# maxit control parameter: maximum number of iteration to allow for\n#   convergence\n# useOptim whether to use optim on rows which have not converged:\n#   Fisher scoring is not ideal with multiple groups and sparse\n#   count distributions\n# useQR whether to use the QR decomposition on the design matrix X\n# forceOptim whether to use optim on all rows\n# warnNonposVar whether to warn about non positive variances,\n#   for advanced users only running LRT without beta prior,\n#   this might be desirable to be ignored.\n#\n# return a list of results, with coefficients and standard\n# errors on the log2 scale\nfitNbinomGLMs <- function(object, modelMatrix=NULL, modelFormula, alpha_hat, lambda,\n                          renameCols=TRUE, betaTol=1e-8, maxit=100, useOptim=TRUE,\n                          useQR=TRUE, forceOptim=FALSE, warnNonposVar=TRUE, minmu=0.5,\n                          type = c("DESeq2", "glmGamPoi")) {\n  type <- match.arg(type, c("DESeq2", "glmGamPoi"))\n  \n  if (missing(modelFormula)) {\n    modelFormula <- design(object)\n  }\n  if (is.null(modelMatrix)) {\n    modelAsFormula <- TRUE\n    modelMatrix <- stats::model.matrix.default(modelFormula, data=as.data.frame(colData(object)))\n  } else {\n    modelAsFormula <- FALSE\n  }\n\n  stopifnot(all(colSums(abs(modelMatrix)) > 0))\n\n  # rename columns, for use as columns in DataFrame\n  # and to emphasize the reference level comparison\n  modelMatrixNames <- colnames(modelMatrix)\n  modelMatrixNames[modelMatrixNames == "(Intercept)"] <- "Intercept"\n  modelMatrixNames <- make.names(modelMatrixNames)\n  \n  if (renameCols) {\n    convertNames <- renameModelMatrixColumns(colData(object),\n                                             modelFormula)\n    convertNames <- convertNames[convertNames$from %in% modelMatrixNames,,drop=FALSE]\n    modelMatrixNames[match(convertNames$from, modelMatrixNames)] <- convertNames$to\n  }\n  colnames(modelMatrix) <- modelMatrixNames\n  \n  normalizationFactors <- getSizeOrNormFactors(object)\n  \n  if (missing(alpha_hat)) {\n    alpha_hat <- dispersions(object)\n  }\n\n  if (length(alpha_hat) != nrow(object)) {\n    stop("alpha_hat needs to be the same length as nrows(object)")\n  }\n\n  # set a wide prior for all coefficients\n  if (missing(lambda)) {\n    lambda <- rep(1e-6, ncol(modelMatrix))\n  }\n\n  # use weights if they are present in assays(object)\n  wlist <- getAndCheckWeights(object, modelMatrix)\n  weights <- wlist$weights\n  useWeights <- wlist$useWeights\n  \n  if(type == "glmGamPoi"){\n    stopifnot("type = \'glmGamPoi\' cannot handle weights" = ! useWeights,\n              "type = \'glmGamPoi\' does not support NA\'s in alpha_hat" = all(! is.na(alpha_hat))) \n    gp_res <- glmGamPoi::glm_gp(counts(object), design = modelMatrix,\n                                size_factors = FALSE, offset = log(normalizationFactors),\n                                overdispersion = alpha_hat, verbose = FALSE)\n    logLikeMat <- dnbinom(counts(object), mu=gp_res$Mu, size=1/alpha_hat, log=TRUE)\n    logLike <- rowSums(logLikeMat)\n    res <- list(logLike = logLike, betaConv =  rep(TRUE, nrow(object)), betaMatrix = gp_res$Beta / log(2),\n                betaSE = NULL, mu = gp_res$Mu, betaIter = rep(NA,nrow(object)),\n                modelMatrix=modelMatrix, \n                nterms=ncol(modelMatrix), hat_diagonals = NULL)\n    return(res)\n  }\n  \n  # bypass the beta fitting if the model formula is only intercept and\n  # the prior variance is large (1e6)\n  # i.e., LRT with reduced ~ 1 and no beta prior\n  justIntercept <- if (modelAsFormula) {\n    modelFormula == formula(~ 1)\n  } else {\n    ncol(modelMatrix) == 1 & all(modelMatrix == 1)\n  }\n  if (justIntercept & all(lambda <= 1e-6)) {\n      alpha <- alpha_hat\n      betaConv <- rep(TRUE, nrow(object))\n      betaIter <- rep(1,nrow(object))\n      betaMatrix <- if (useWeights) {\n                      matrix(log2(rowSums(weights*counts(object, normalized=TRUE))\n                                  /rowSums(weights)),ncol=1)\n                    } else {\n                      matrix(log2(rowMeans(counts(object, normalized=TRUE))),ncol=1)\n                    }\n      mu <- normalizationFactors * as.numeric(2^betaMatrix)\n      logLikeMat <- dnbinom(counts(object), mu=mu, size=1/alpha, log=TRUE)\n      logLike <- if (useWeights) {\n                   rowSums(weights*logLikeMat)\n                 } else {\n                   rowSums(logLikeMat)\n                 }\n      modelMatrix <- stats::model.matrix.default(~ 1, data=as.data.frame(colData(object)))\n      colnames(modelMatrix) <- modelMatrixNames <- "Intercept"\n      w <- if (useWeights) {\n             weights * (mu^-1 + alpha)^-1\n           } else {\n             (mu^-1 + alpha)^-1\n           }\n      xtwx <- rowSums(w)\n      sigma <- xtwx^-1\n      betaSE <- matrix(log2(exp(1)) * sqrt(sigma),ncol=1)      \n      hat_diagonals <- w * xtwx^-1;\n      res <- list(logLike = logLike, betaConv = betaConv, betaMatrix = betaMatrix,\n                  betaSE = betaSE, mu = mu, betaIter = betaIter,\n                  modelMatrix=modelMatrix, \n                  nterms=1, hat_diagonals=hat_diagonals)\n      return(res)\n  }\n  \n  qrx <- qr(modelMatrix)\n  # if full rank, estimate initial betas for IRLS below\n  if (qrx$rank == ncol(modelMatrix)) {\n    Q <- qr.Q(qrx)\n    R <- qr.R(qrx)\n    y <- t(log(counts(object,normalized=TRUE) + .1))\n    beta_mat <- t(solve(R, t(Q) %*% y))\n  } else {\n    if ("Intercept" %in% modelMatrixNames) {\n      beta_mat <- matrix(0, ncol=ncol(modelMatrix), nrow=nrow(object))\n      # use the natural log as fitBeta occurs in the natural log scale\n      logBaseMean <- log(rowMeans(counts(object,normalized=TRUE)))\n      beta_mat[,which(modelMatrixNames == "Intercept")] <- logBaseMean\n    } else {\n      beta_mat <- matrix(1, ncol=ncol(modelMatrix), nrow=nrow(object))\n    }\n  }\n  \n  # here we convert from the log2 scale of the betas\n  # and the beta prior variance to the log scale\n  # used in fitBeta.\n  # so we divide by the square of the\n  # conversion factor, log(2)\n  lambdaNatLogScale <- lambda / log(2)^2\n  \n  betaRes <- fitBetaWrapper(ySEXP = counts(object), xSEXP = modelMatrix,\n                            nfSEXP = normalizationFactors,\n                            alpha_hatSEXP = alpha_hat,\n                            beta_matSEXP = beta_mat,\n                            lambdaSEXP = lambdaNatLogScale,\n                            weightsSEXP = weights,\n                            useWeightsSEXP = useWeights,\n                            tolSEXP = betaTol, maxitSEXP = maxit,\n                            useQRSEXP=useQR, minmuSEXP=minmu)\n\n  # Note on deviance: the \'deviance\' calculated in fitBeta() (C++)\n  # is not returned in mcols(object)$deviance. instead, we calculate\n  # the log likelihood below and use -2 * logLike.\n  # (reason is that we have other ways of estimating beta:\n  # above intercept code, and below optim code)\n  \n  mu <- normalizationFactors * t(exp(modelMatrix %*% t(betaRes$beta_mat)))\n  dispersionVector <- rep(dispersions(object), times=ncol(object))\n  logLike <- nbinomLogLike(counts(object), mu, dispersions(object), weights, useWeights)\n\n  # test for stability\n  rowStable <- apply(betaRes$beta_mat,1,function(row) sum(is.na(row))) == 0\n\n  # test for positive variances\n  rowVarPositive <- apply(betaRes$beta_var_mat,1,function(row) sum(row <= 0)) == 0\n  \n  # test for convergence, stability and positive variances\n  betaConv <- betaRes$iter < maxit\n  \n  # here we transform the betaMatrix and betaSE to a log2 scale\n  betaMatrix <- log2(exp(1))*betaRes$beta_mat\n  colnames(betaMatrix) <- modelMatrixNames\n  colnames(modelMatrix) <- modelMatrixNames\n  # warn below regarding these rows with negative variance\n  betaSE <- log2(exp(1))*sqrt(pmax(betaRes$beta_var_mat,0))\n  colnames(betaSE) <- paste0("SE_",modelMatrixNames)\n\n  # switch based on whether we should also use optim\n  # on rows which did not converge\n  rowsForOptim <- if (useOptim) {\n    which(!betaConv | !rowStable | !rowVarPositive)\n  } else {\n    which(!rowStable | !rowVarPositive)\n  }\n  \n  if (forceOptim) {\n    rowsForOptim <- seq_along(betaConv)\n  }\n  \n  if (length(rowsForOptim) > 0) {\n    # we use optim if didn\'t reach convergence with the IRLS code\n    resOptim <- fitNbinomGLMsOptim(object,modelMatrix,lambda,\n                                   rowsForOptim,rowStable,\n                                   normalizationFactors,alpha_hat,\n                                   weights,useWeights,\n                                   betaMatrix,betaSE,betaConv,\n                                   beta_mat,\n                                   mu,logLike,minmu=minmu)\n    betaMatrix <- resOptim$betaMatrix\n    betaSE <- resOptim$betaSE\n    betaConv <- resOptim$betaConv\n    mu <- resOptim$mu\n    logLike <- resOptim$logLike\n  }\n\n  stopifnot(!any(is.na(betaSE)))\n  nNonposVar <- sum(rowSums(betaSE == 0) > 0)\n  if (warnNonposVar & nNonposVar > 0) warning(nNonposVar,"rows had non-positive estimates of variance for coefficients")\n  \n  list(logLike = logLike, betaConv = betaConv, betaMatrix = betaMatrix,\n       betaSE = betaSE, mu = mu, betaIter = betaRes$iter, modelMatrix=modelMatrix, \n       nterms=ncol(modelMatrix), hat_diagonals=betaRes$hat_diagonals)\n}\n\n# this function calls fitNbinomGLMs() twice:\n# 1 - without the beta prior, in order to calculate the\n#     beta prior variance and hat matrix\n# 2 - again but with the prior in order to get beta matrix and standard errors\nfitGLMsWithPrior <- function(object, betaTol, maxit, useOptim, useQR, betaPriorVar, modelMatrix=NULL, minmu=0.5) {\n  \n  objectNZ <- object[!mcols(object)$allZero,,drop=FALSE]\n  modelMatrixType <- attr(object, "modelMatrixType")\n\n  if (missing(betaPriorVar) | !(all(c("mu","H") %in% assayNames(objectNZ)))) {\n\n    # stop unless modelMatrix was NOT supplied, the code below all works\n    # by building model matrices using the formula, doesn\'t work with incoming model matrices\n    stopifnot(is.null(modelMatrix))\n    \n    # fit the negative binomial GLM without a prior,\n    # used to construct the prior variances\n    # and for the hat matrix diagonals for calculating Cook\'s distance\n    fit <- fitNbinomGLMs(objectNZ,\n                         betaTol=betaTol, maxit=maxit,\n                         useOptim=useOptim, useQR=useQR,\n                         renameCols = (modelMatrixType == "standard"),\n                         minmu=minmu)\n    modelMatrix <- fit$modelMatrix\n    modelMatrixNames <- colnames(modelMatrix)\n    H <- fit$hat_diagonal\n    betaMatrix <- fit$betaMatrix\n    mu <- fit$mu\n\n    modelMatrixNames[modelMatrixNames == "(Intercept)"] <- "Intercept"\n    modelMatrixNames <- make.names(modelMatrixNames)\n    colnames(betaMatrix) <- modelMatrixNames\n    \n    # save the MLE log fold changes for addMLE argument of results\n    convertNames <- renameModelMatrixColumns(colData(object),\n                                             design(objectNZ))\n    convertNames <- convertNames[convertNames$from %in% modelMatrixNames,,drop=FALSE]\n    modelMatrixNames[match(convertNames$from, modelMatrixNames)] <- convertNames$to\n    mleBetaMatrix <- fit$betaMatrix\n    colnames(mleBetaMatrix) <- paste0("MLE_",modelMatrixNames)\n\n    # store for use in estimateBetaPriorVar below\n    mcols(objectNZ) <- cbind(mcols(objectNZ), DataFrame(mleBetaMatrix))\n  } else {\n    # we can skip the first MLE fit because the\n    # beta prior variance and hat matrix diagonals were provided\n    if (is.null(modelMatrix)) {\n      modelMatrix <- getModelMatrix(object)\n    }\n    H <- assays(objectNZ)[["H"]]\n    mu <- assays(objectNZ)[["mu"]]\n    mleBetaMatrix <- as.matrix(mcols(objectNZ)[,grep("MLE_",names(mcols(objectNZ))),drop=FALSE])\n  }\n     \n  if (missing(betaPriorVar)) {\n    betaPriorVar <- estimateBetaPriorVar(objectNZ, modelMatrix=modelMatrix)\n  } else {\n    # else we are provided the prior variance:\n    # check if the lambda is the correct length\n    # given the design formula\n    if (modelMatrixType == "expanded") {\n      modelMatrix <- makeExpandedModelMatrix(objectNZ)\n    }\n    p <- ncol(modelMatrix)\n    if (length(betaPriorVar) != p) {\n      stop(paste("betaPriorVar should have length",p,"to match:",paste(colnames(modelMatrix),collapse=", ")))\n    }\n  }\n  \n  # refit the negative binomial GLM with a prior on betas\n  if (any(betaPriorVar == 0)) {\n    stop("beta prior variances are equal to zero for some variables")\n  }\n  lambda <- 1/betaPriorVar\n\n  if (modelMatrixType == "standard") {\n    fit <- fitNbinomGLMs(objectNZ, lambda=lambda,\n                         betaTol=betaTol, maxit=maxit,\n                         useOptim=useOptim, useQR=useQR,\n                         minmu=minmu)\n    modelMatrix <- fit$modelMatrix\n  } else if (modelMatrixType == "expanded") {\n    modelMatrix <- makeExpandedModelMatrix(objectNZ)\n    fit <- fitNbinomGLMs(objectNZ, lambda=lambda,\n                         betaTol=betaTol, maxit=maxit,\n                         useOptim=useOptim, useQR=useQR,\n                         modelMatrix=modelMatrix, renameCols=FALSE,\n                         minmu=minmu)\n  } else if (modelMatrixType == "user-supplied") {\n    fit <- fitNbinomGLMs(objectNZ, lambda=lambda,\n                         betaTol=betaTol, maxit=maxit,\n                         useOptim=useOptim, useQR=useQR,\n                         modelMatrix=modelMatrix, renameCols=FALSE,\n                         minmu=minmu)\n  }\n\n  res <- list(fit=fit, H=H, betaPriorVar=betaPriorVar, mu=mu,\n              modelMatrix=modelMatrix, mleBetaMatrix=mleBetaMatrix)\n  res\n}\n\n# breaking out the optim backup code from fitNbinomGLMs\nfitNbinomGLMsOptim <- function(object,modelMatrix,lambda,\n                               rowsForOptim,rowStable,\n                               normalizationFactors,alpha_hat,\n                               weights,useWeights,\n                               betaMatrix,betaSE,betaConv,\n                               beta_mat,\n                               mu,logLike,minmu=0.5) {\n  x <- modelMatrix\n  lambdaNatLogScale <- lambda / log(2)^2\n  large <- 30\n  for (row in rowsForOptim) {\n    betaRow <- if (rowStable[row] & all(abs(betaMatrix[row,]) < large)) {\n      betaMatrix[row,]\n    } else {\n      beta_mat[row,]\n    }\n    nf <- normalizationFactors[row,]\n    k <- counts(object)[row,]\n    alpha <- alpha_hat[row]\n    objectiveFn <- function(p) {\n      mu_row <- as.numeric(nf * 2^(x %*% p))\n      logLikeVector <- dnbinom(k,mu=mu_row,size=1/alpha,log=TRUE)\n      logLike <- if (useWeights) {\n                   sum(weights[row,] * logLikeVector)\n                 } else {\n                   sum(logLikeVector)\n                 }\n      logPrior <- sum(dnorm(p,0,sqrt(1/lambda),log=TRUE))\n      negLogPost <- -1 * (logLike + logPrior)\n      if (is.finite(negLogPost)) negLogPost else 10^300\n    }\n    o <- optim(betaRow, objectiveFn, method="L-BFGS-B",lower=-large, upper=large)\n    ridge <- if (length(lambdaNatLogScale) > 1) {\n      diag(lambdaNatLogScale)\n    } else {\n      as.matrix(lambdaNatLogScale,ncol=1)\n    }\n    # if we converged, change betaConv to TRUE\n    if (o$convergence == 0) {\n      betaConv[row] <- TRUE\n    }\n    # with or without convergence, store the estimate from optim\n    betaMatrix[row,] <- o$par\n    # calculate the standard errors\n    mu_row <- as.numeric(nf * 2^(x %*% o$par))\n    # store the new mu vector\n    mu[row,] <- mu_row\n    mu_row[mu_row < minmu] <- minmu\n    w <- if (useWeights) {\n           diag(weights[row,] * (mu_row^-1 + alpha)^-1)\n         } else {\n           diag((mu_row^-1 + alpha)^-1)\n         }\n    xtwx <- t(x) %*% w %*% x\n    xtwxRidgeInv <- solve(xtwx + ridge)\n    sigma <- xtwxRidgeInv %*% xtwx %*% xtwxRidgeInv\n    # warn below regarding these rows with negative variance\n    betaSE[row,] <- log2(exp(1)) * sqrt(pmax(diag(sigma),0))\n    logLikeVector <- dnbinom(k,mu=mu_row,size=1/alpha,log=TRUE)\n    logLike[row] <- if (useWeights) {\n                      sum(weights[row,] * logLikeVector)\n                    } else {\n                      sum(logLikeVector)\n                    }\n  }\n  return(list(betaMatrix=betaMatrix,betaSE=betaSE,\n              betaConv=betaConv,mu=mu,logLike=logLike))\n}\n'