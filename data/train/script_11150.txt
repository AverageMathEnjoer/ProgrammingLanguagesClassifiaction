b'#\' emlinklog\n#\'\n#\' Expectation-Maximization algorithm for Record Linkage \n#\' allowing for dependencies across linkage fields\n#\'\n#\' @usage emlinklog(patterns, nobs.a, nobs.b, p.m, p.gamma.j.m, p.gamma.j.u,\n#\' iter.max, tol, varnames)\n#\'\n#\' @param patterns table that holds the counts for each unique agreement\n#\' pattern. This object is produced by the function: tableCounts.\n#\' @param nobs.a Number of observations in dataset A\n#\' @param nobs.b Number of observations in dataset B\n#\' @param p.m probability of finding a match. Default is 0.1\n#\' @param p.gamma.j.m probability that conditional of being in the matched set we observed a specific agreement pattern.\n#\' @param p.gamma.j.u probability that conditional of being in the non-matched set we observed a specific agreement pattern.\n#\' @param iter.max Max number of iterations. Default is 5000\n#\' @param tol Convergence tolerance. Default is 1e-05\n#\' @param varnames The vector of variable names used for matching. Automatically provided if using \\code{fastLink()} wrapper. Used for\n#\' clean visualization of EM results in summary functions.\n#\'\n#\' @return \\code{emlinklog} returns a list with the following components:\n#\' \\item{zeta.j}{The posterior match probabilities for each unique pattern.}\n#\' \\item{p.m}{The probability of finding a match.}\n#\' \\item{p.u}{The probability of finding a non-match.}\n#\' \\item{p.gamma.j.m}{The probability of observing a particular agreement pattern conditional on being in the set of matches.}\n#\' \\item{p.gamma.j.u}{The probability of observing a particular agreement pattern conditional on being in the set of non-matches.}\n#\' \\item{patterns.w}{Counts of the agreement patterns observed, along with the Felligi-Sunter Weights.}\n#\' \\item{iter.converge}{The number of iterations it took the EM algorithm to converge.}\n#\' \\item{nobs.a}{The number of observations in dataset A.}\n#\' \\item{nobs.b}{The number of observations in dataset B.}\n#\'\n#\' @author Ted Enamorado <ted.enamorado@gmail.com> and Benjamin Fifield\n#\'\n#\' @examples\n#\' \\dontrun{\n#\' ## Calculate gammas\n#\' g1 <- gammaCKpar(dfA$firstname, dfB$firstname)\n#\' g2 <- gammaCKpar(dfA$middlename, dfB$middlename)\n#\' g3 <- gammaCKpar(dfA$lastname, dfB$lastname)\n#\' g4 <- gammaKpar(dfA$birthyear, dfB$birthyear)\n#\'\n#\' ## Run tableCounts\n#\' tc <- tableCounts(list(g1, g2, g3, g4), nobs.a = nrow(dfA), nobs.b = nrow(dfB))\n#\'\n#\' ## Run EM\n#\' em.log <- emlinklog(tc, nobs.a = nrow(dfA), nobs.b = nrow(dfB))\n#\' }\n#\'\n#\' @export\n#\' @importFrom gtools rdirichlet\n#\' @importFrom stats glm model.matrix\nemlinklog <- function(patterns, nobs.a, nobs.b,\n                      p.m = 0.1, p.gamma.j.m = NULL, p.gamma.j.u = NULL, iter.max = 5000, tol = 1e-5, varnames = NULL) {\n\n    ## OPTIONS  \n    ## patterns <- tc; nobs.a <- nrow(dfA); nobs.a <- nrow(dfB); p.m <- 0.1; iter.max = 5000; \n    ## tol = 1e-5; p.gamma.k.m = NULL; p.gamma.k.u = NULL\n\n    options(digits=16)\n    \n    ## EM Algorithm for a Fellegi-Sunter model that accounts for missing data (under MAR)\n    ##\n    ## Args:\n    ##   patterns:\n    ##   p.m:\n    ##   p.gamma.k.m:\n    ##   p.gamma.k.u:\n    ##   tol:\n    ##\n    ## Returns:\n    ##   The p.m, p.gamma.k.m, p.gamma.k.u, p.gamma.k.m, p.gamma.k.m, p.gamma.k.m, that\n    ##   maximize the observed data log-likelihood of the agreement patterns\n\n    ## Edge case\n    if(is.null(nrow(patterns))){\n        patterns <- as.data.frame(t(as.matrix(patterns)))\n    }\n    \n    ## Number of fields\n    nfeatures <- ncol(patterns) - 1\n    \n    ## Patterns:\n    gamma.j.k <- as.matrix(patterns[, 1:nfeatures])\n\n    ## Patterns counts:\n    n.j <- as.matrix(patterns[, (nfeatures + 1)])  # Counts\n    \n    ## Number of unique patterns:\n    N <- nrow(gamma.j.k)\n    \n    p.gamma.k.m <- p.gamma.k.u <- NULL\n    \n    ## Overall Prob of finding a Match\n    p.u <- 1 - p.m\n    \n    ## Field specific probability of observing gamma.k conditional on M\n    if (is.null(p.gamma.k.m)) {\n        p.gamma.k.m <- list()\n        for (i in 1:nfeatures) {\n            l.m <- length(unique(na.omit(gamma.j.k[, i])))\n            c.m <- seq(from = 1, to = 50 * l.m, by = 50)\n            p.gamma.k.m[[i]] <- sort(rdirichlet(1, c.m), decreasing = FALSE)\n        }\n    }\n\n    ## Field specific probability of observing gamma.k conditional on U\n    if (is.null(p.gamma.k.u)) {\n        p.gamma.k.u <- list()\n        for (i in 1:nfeatures) {\n            l.u <- length(unique(na.omit(gamma.j.k[, i])))\n            c.u <- seq(from = 1, to = 50 * l.u, by = 50)\n            p.gamma.k.u[[i]] <- sort(rdirichlet(1, c.u), decreasing = TRUE)\n        }\n    }\n    \n    p.gamma.k.j.m <- matrix(rep(NA, N * nfeatures), nrow = nfeatures, ncol = N)\n    p.gamma.k.j.u <- matrix(rep(NA, N * nfeatures), nrow = nfeatures, ncol = N)\n    \n    p.gamma.j.m <- matrix(rep(NA, N), nrow = N, ncol = 1)\n    p.gamma.j.u <- matrix(rep(NA, N), nrow = N, ncol = 1)\n    \n    for (i in 1:nfeatures) {\n        temp.01 <- temp.02 <- gamma.j.k[, i]\n        temp.1 <- unique(na.omit(temp.01))\n        temp.2 <- p.gamma.k.m[[i]]\n        temp.3 <- p.gamma.k.u[[i]]\n        for (j in 1:length(temp.1)) {\n            temp.01[temp.01 == temp.1[j]] <- temp.2[j]\n            temp.02[temp.02 == temp.1[j]] <- temp.3[j]\n        }\n        p.gamma.k.j.m[i, ] <- temp.01\n        p.gamma.k.j.u[i, ] <- temp.02\n    }\n    \n    sumlog <- function(x) { sum(log(x), na.rm = T) }\n    \n    p.gamma.j.m <- as.matrix((apply(p.gamma.k.j.m, 2, sumlog)))\n    p.gamma.j.m <- exp(p.gamma.j.m)\n    \n    p.gamma.j.u <- as.matrix((apply(p.gamma.k.j.u, 2, sumlog)))\n    p.gamma.j.u <- exp(p.gamma.j.u)\n\n    delta <- 1\n    count <- 1\n    warn.once <- 1\n    \n    ## The EM Algorithm presented in the paper starts here:\n    while (abs(delta) >= tol) {\n        \n        if((count %% 100) == 0) {\n            cat("Iteration number", count, "\\n")\n            cat("Maximum difference in log-likelihood =", round(delta, 4), "\\n")\n        }\n        \n        ## Old Paramters\n        p.old <- c(p.m, p.u, unlist(p.gamma.j.m), unlist(p.gamma.j.u))\n\n        ## ------\n        ## E-Step:\n        ## ------\n        \n        log.prod <- log(p.gamma.j.m) + log(p.m)\n        max.log.prod <- max(log.prod)\n        \n        logxpy <- function(lx,ly) {\n            temp <- cbind(lx, ly)\n            apply(temp, 1, max) + log1p(exp(-abs(lx-ly)))\n        }\n        \n        log.sum <- logxpy(log(p.gamma.j.m) + log(p.m), log(p.gamma.j.u) + log(p.u))\n        zeta.j <- exp(log.prod - max.log.prod)/(exp(log.sum - max.log.prod))\n        \n        ## --------\n        ## M-step :\n        ## --------\n        num.prod <- n.j * zeta.j\n        p.m <- sum(num.prod)/sum(n.j)\n        p.u <- 1 - p.m\n        \n\n        pat <- data.frame(gamma.j.k)\n        pat[is.na(pat)] <- -1\n        pat <- replace(pat, TRUE, lapply(pat, factor))\n        factors <- model.matrix(~ ., pat)\n        \n        ## get theta.m and theta.u\n        c <- 1e-06\n        matches <- glm(count ~ ., data = data.frame(count = ((zeta.j * n.j) + c), factors),\n                       family = "quasipoisson")\n\n        non.matches <- glm(count ~ .*., data = data.frame(count = ((1 - zeta.j) * n.j + c), factors),\n                           family = "quasipoisson")\n        \n        ## Predict & renormalization fn as in Murray 2017\n        g <- function(fit) {\n            logwt = predict( fit )\n            logwt = logwt - max(logwt)\n            wt = exp(logwt)\n            wt/sum(wt)\n        }\n\n        p.gamma.j.m = as.matrix(g(matches))\n        p.gamma.j.u = as.matrix(g(non.matches))\n\n        ## Updated parameters:\n        p.new <- c(p.m, p.u, unlist(p.gamma.j.m), unlist(p.gamma.j.u))\n        \n        if(p.m < 1e-13 & warn.once == 1) {\n            warning("The overall probability of finding a match is too small. Increasing the amount of overlap between the datasets might help, see e.g., clusterMatch()")\n            warn.once <- 0\n        }\n        \n        ## Max difference between the updated and old parameters:\n        delta <- max(abs(p.new - p.old))\n        count <- count + 1\n        \n        if(count > iter.max) {\n            warning("The EM algorithm has run for the specified number of iterations but has not converged yet.")\n            break\n        }\n    }\n    \n    weights <- log(p.gamma.j.m) - log(p.gamma.j.u)\n    \n    data.w <- cbind(patterns, weights, p.gamma.j.m, p.gamma.j.u)\n    nc <- ncol(data.w)\n    colnames(data.w)[nc-2] <- "weights"\n    colnames(data.w)[nc-1] <- "p.gamma.j.m"\n    colnames(data.w)[nc] <- "p.gamma.j.u"\n    \n    inf <- which(data.w == Inf, arr.ind = T)\n    ninf <- which(data.w == -Inf, arr.ind = T)\n    \n    data.w[inf[, 1], unique(inf[, 2])] <- 150\n    data.w[ninf[, 1], unique(ninf[, 2])] <- -150\n\n    if(!is.null(varnames)){\n        output <- list("zeta.j"= zeta.j,"p.m"= p.m, "p.u" = p.u, \n                       "p.gamma.j.m" = p.gamma.j.m, "p.gamma.j.u" = p.gamma.j.u, "patterns.w" = data.w, "iter.converge" = count,\n                       "nobs.a" = nobs.a, "nobs.b" = nobs.b, "varnames" = varnames)\n    }else{\n        output <- list("zeta.j"= zeta.j,"p.m"= p.m, "p.u" = p.u, \n                       "p.gamma.j.m" = p.gamma.j.m, "p.gamma.j.u" = p.gamma.j.u, "patterns.w" = data.w, "iter.converge" = count,\n                       "nobs.a" = nobs.a, "nobs.b" = nobs.b, "varnames" = paste0("gamma.", 1:nfeatures))\n    }\n\n    \n    class(output) <- c("fastLink", "fastLink.EM")\n    \n    return(output)\n}\n'