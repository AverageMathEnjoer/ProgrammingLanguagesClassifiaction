b'{-# LANGUAGE DataKinds #-}\n{-# LANGUAGE QuasiQuotes #-}\n{-# LANGUAGE Rank2Types #-}\n{-# LANGUAGE ScopedTypeVariables #-}\n{-# LANGUAGE TypeOperators #-}\n\n{- This is a standalone module so it shouldn\'t depend on any CLI state like Env -}\nmodule Cachix.Client.Push\n  ( -- * Pushing a single path\n    pushSingleStorePath,\n    uploadStorePath,\n    PushParams (..),\n    PushSecret (..),\n    PushStrategy (..),\n    defaultWithXzipCompressor,\n    defaultWithXzipCompressorWithLevel,\n    defaultWithZstdCompressor,\n    defaultWithZstdCompressorWithLevel,\n    findPushSecret,\n\n    -- * Pushing a closure of store paths\n    pushClosure,\n    getMissingPathsForClosure,\n    mapConcurrentlyBounded,\n  )\nwhere\n\nimport qualified Cachix.API as API\nimport Cachix.API.Error\nimport Cachix.API.Signing (fingerprint, passthroughHashSink, passthroughHashSinkB16, passthroughSizeSink)\nimport qualified Cachix.Client.Config as Config\nimport Cachix.Client.Exception (CachixException (..))\nimport qualified Cachix.Client.Push.S3 as Push.S3\nimport Cachix.Client.Retry (retryAll)\nimport Cachix.Client.Secrets\nimport Cachix.Client.Servant\nimport qualified Cachix.Types.BinaryCache as BinaryCache\nimport qualified Cachix.Types.MultipartUpload as Multipart\nimport qualified Cachix.Types.NarInfoCreate as Api\nimport qualified Cachix.Types.NarInfoHash as NarInfoHash\nimport Control.Concurrent.Async (mapConcurrently)\nimport qualified Control.Concurrent.QSem as QSem\nimport Control.Exception.Safe (MonadMask, throwM)\nimport Control.Monad.Trans.Resource (ResourceT)\nimport Control.Retry (RetryStatus)\nimport Crypto.Sign.Ed25519\nimport qualified Data.ByteString.Base64 as B64\nimport Data.Conduit\nimport qualified Data.Conduit.Lzma as Lzma (compress)\nimport qualified Data.Conduit.Zstd as Zstd (compress)\nimport Data.IORef\nimport qualified Data.Set as Set\nimport Data.String.Here\nimport qualified Data.Text as T\nimport Hercules.CNix (StorePath)\nimport qualified Hercules.CNix.Std.Set as Std.Set\nimport Hercules.CNix.Store (Store)\nimport qualified Hercules.CNix.Store as Store\nimport Network.HTTP.Types (status401, status404)\nimport Protolude hiding (toS)\nimport Protolude.Conv\nimport Servant.API\nimport Servant.Auth ()\nimport Servant.Auth.Client\nimport Servant.Client.Streaming\nimport Servant.Conduit ()\nimport System.Environment (lookupEnv)\nimport qualified System.Nix.Base32\nimport System.Nix.Nar\n\ndata PushSecret\n  = PushToken Token\n  | PushSigningKey Token SigningKey\n\ndata PushParams m r = PushParams\n  { pushParamsName :: Text,\n    pushParamsSecret :: PushSecret,\n    -- | how to report results, (some) errors, and do some things\n    pushParamsStrategy :: StorePath -> PushStrategy m r,\n    -- | cachix base url, connection manager, see \'Cachix.Client.URI.defaultCachixBaseUrl\', \'Servant.Client.mkClientEnv\'\n    pushParamsClientEnv :: ClientEnv,\n    pushParamsStore :: Store\n  }\n\ndata PushStrategy m r = PushStrategy\n  { -- | Called when a path is already in the cache.\n    onAlreadyPresent :: m r,\n    onAttempt :: RetryStatus -> Int64 -> m (),\n    on401 :: ClientError -> m r,\n    onError :: ClientError -> m r,\n    onDone :: m r,\n    compressionMethod :: BinaryCache.CompressionMethod,\n    compressionLevel :: Int,\n    omitDeriver :: Bool\n  }\n\ndefaultWithXzipCompressor :: forall m a. (ConduitM ByteString ByteString (ResourceT IO) () -> m a) -> m a\ndefaultWithXzipCompressor = ($ Lzma.compress (Just 2))\n\ndefaultWithXzipCompressorWithLevel :: Int -> forall m a. (ConduitM ByteString ByteString (ResourceT IO) () -> m a) -> m a\ndefaultWithXzipCompressorWithLevel l = ($ Lzma.compress (Just l))\n\ndefaultWithZstdCompressor :: forall m a. (ConduitM ByteString ByteString (ResourceT IO) () -> m a) -> m a\ndefaultWithZstdCompressor = ($ Zstd.compress 8)\n\ndefaultWithZstdCompressorWithLevel :: Int -> forall m a. (ConduitM ByteString ByteString (ResourceT IO) () -> m a) -> m a\ndefaultWithZstdCompressorWithLevel l = ($ Zstd.compress l)\n\npushSingleStorePath ::\n  (MonadMask m, MonadIO m) =>\n  -- | details for pushing to cache\n  PushParams m r ->\n  -- | store path\n  StorePath ->\n  -- | r is determined by the \'PushStrategy\'\n  m r\npushSingleStorePath cache storePath = retryAll $ \\retrystatus -> do\n  storeHash <- liftIO $ Store.getStorePathHash storePath\n  let name = pushParamsName cache\n      strategy = pushParamsStrategy cache storePath\n  -- Check if narinfo already exists\n  res <-\n    liftIO $\n      (`runClientM` pushParamsClientEnv cache) $\n        API.narinfoHead\n          cachixClient\n          (getCacheAuthToken (pushParamsSecret cache))\n          name\n          (NarInfoHash.NarInfoHash (decodeUtf8With lenientDecode storeHash))\n  case res of\n    Right NoContent -> onAlreadyPresent strategy -- we\'re done as store path is already in the cache\n    Left err\n      | isErr err status404 -> uploadStorePath cache storePath retrystatus\n      | isErr err status401 -> on401 strategy err\n      | otherwise -> onError strategy err\n\ngetCacheAuthToken :: PushSecret -> Token\ngetCacheAuthToken (PushToken token) = token\ngetCacheAuthToken (PushSigningKey token _) = token\n\nuploadStorePath ::\n  (MonadIO m) =>\n  -- | details for pushing to cache\n  PushParams m r ->\n  StorePath ->\n  RetryStatus ->\n  -- | r is determined by the \'PushStrategy\'\n  m r\nuploadStorePath cache storePath retrystatus = do\n  let store = pushParamsStore cache\n  -- TODO: storePathText is redundant. Use storePath directly.\n  storePathText <- liftIO $ Store.storePathToPath store storePath\n  let (storeHash, storeSuffix) = splitStorePath $ toS storePathText\n      cacheName = pushParamsName cache\n      authToken = getCacheAuthToken (pushParamsSecret cache)\n      clientEnv = pushParamsClientEnv cache\n      strategy = pushParamsStrategy cache storePath\n      withCompressor = case compressionMethod strategy of\n        BinaryCache.XZ -> defaultWithXzipCompressorWithLevel (compressionLevel strategy)\n        BinaryCache.ZSTD -> defaultWithZstdCompressorWithLevel (compressionLevel strategy)\n      cacheClientEnv =\n        clientEnv\n          { baseUrl = (baseUrl clientEnv) {baseUrlHost = toS cacheName <> "." <> baseUrlHost (baseUrl clientEnv)}\n          }\n\n  narSizeRef <- liftIO $ newIORef 0\n  fileSizeRef <- liftIO $ newIORef 0\n  narHashRef <- liftIO $ newIORef ("" :: ByteString)\n  fileHashRef <- liftIO $ newIORef ("" :: ByteString)\n\n  -- This should be a noop because storePathText came from a StorePath\n  normalized <- liftIO $ Store.followLinksToStorePath store $ toS storePathText\n  pathinfo <- liftIO $ Store.queryPathInfo store normalized\n  let storePathSize = Store.validPathInfoNarSize pathinfo\n  onAttempt strategy retrystatus storePathSize\n\n  withCompressor $ \\compressor -> liftIO $ do\n    uploadResult <-\n      runConduitRes $\n        streamNarIO narEffectsIO (toS storePathText) Data.Conduit.yield\n          .| passthroughSizeSink narSizeRef\n          .| passthroughHashSink narHashRef\n          .| compressor\n          .| passthroughSizeSink fileSizeRef\n          .| passthroughHashSinkB16 fileHashRef\n          .| Push.S3.streamUpload cacheClientEnv authToken cacheName (compressionMethod strategy)\n\n    case uploadResult of\n      Left err -> throwIO err\n      Right (narId, uploadId, parts) -> do\n        narSize <- readIORef narSizeRef\n        narHash <- ("sha256:" <>) . System.Nix.Base32.encode <$> readIORef narHashRef\n        narHashNix <- Store.validPathInfoNarHash32 pathinfo\n        when (narHash /= toS narHashNix) $ throwM $ NarHashMismatch $ toS storePathText <> ": Nar hash mismatch between nix-store --dump and nix db. You can repair db metadata by running as root: $ nix-store --verify --repair --check-contents"\n        fileHash <- readIORef fileHashRef\n        fileSize <- readIORef fileSizeRef\n        deriverPath <-\n          if omitDeriver strategy\n            then pure Nothing\n            else Store.validPathInfoDeriver store pathinfo\n        deriver <- for deriverPath Store.getStorePathBaseName\n        referencesPathSet <- Store.validPathInfoReferences store pathinfo\n        referencesPaths <- sort . fmap toS <$> for referencesPathSet (Store.storePathToPath store)\n        references <- sort . fmap toS <$> for referencesPathSet Store.getStorePathBaseName\n        let fp = fingerprint (decodeUtf8With lenientDecode storePathText) narHash narSize referencesPaths\n            sig = case pushParamsSecret cache of\n              PushToken _ -> Nothing\n              PushSigningKey _ signKey -> Just $ toS $ B64.encode $ unSignature $ dsign (signingSecretKey signKey) fp\n            nic =\n              Api.NarInfoCreate\n                { Api.cStoreHash = storeHash,\n                  Api.cStoreSuffix = storeSuffix,\n                  Api.cNarHash = narHash,\n                  Api.cNarSize = narSize,\n                  Api.cFileSize = fileSize,\n                  Api.cFileHash = toS fileHash,\n                  Api.cReferences = references,\n                  Api.cDeriver = maybe "unknown-deriver" (decodeUtf8With lenientDecode) deriver,\n                  Api.cSig = sig\n                }\n        escalate $ Api.isNarInfoCreateValid nic\n\n        -- Complete the multipart upload and upload the narinfo\n        let completeMultipartUploadRequest =\n              API.completeNarUpload cachixClient authToken cacheName narId uploadId $\n                Multipart.CompletedMultipartUpload\n                  { Multipart.parts = parts,\n                    Multipart.narInfoCreate = nic\n                  }\n        void $ withClientM completeMultipartUploadRequest cacheClientEnv escalate\n\n  onDone strategy\n\n-- | Push an entire closure\n--\n-- Note: \'onAlreadyPresent\' will be called less often in the future.\npushClosure ::\n  (MonadIO m, MonadMask m) =>\n  -- | Traverse paths, responsible for bounding parallel processing of paths\n  --\n  -- For example: @\'mapConcurrentlyBounded\' 4@\n  (forall a b. (a -> m b) -> [a] -> m [b]) ->\n  PushParams m r ->\n  -- | Initial store paths\n  [StorePath] ->\n  -- | Every @r@ per store path of the entire closure of store paths\n  m [r]\npushClosure traversal pushParams inputStorePaths = do\n  missingPaths <- getMissingPathsForClosure pushParams inputStorePaths\n  traversal (\\path -> retryAll $ \\retrystatus -> uploadStorePath pushParams path retrystatus) missingPaths\n\ngetMissingPathsForClosure :: (MonadIO m, MonadMask m) => PushParams m r -> [StorePath] -> m [StorePath]\ngetMissingPathsForClosure pushParams inputPaths = do\n  let store = pushParamsStore pushParams\n      clientEnv = pushParamsClientEnv pushParams\n  -- Get the transitive closure of dependencies\n  (paths :: [Store.StorePath]) <-\n    liftIO $ do\n      inputs <- Std.Set.new\n      for_ inputPaths $ \\path -> do\n        Std.Set.insertFP inputs path\n      closure <- Store.computeFSClosure store Store.defaultClosureParams inputs\n      Std.Set.toListFP closure\n  hashes <- for paths (liftIO . fmap (decodeUtf8With lenientDecode) . Store.getStorePathHash)\n  -- Check what store paths are missing\n  missingHashesList <-\n    retryAll $ \\_ ->\n      escalate\n        =<< liftIO\n          ( (`runClientM` clientEnv) $\n              API.narinfoBulk\n                cachixClient\n                (getCacheAuthToken (pushParamsSecret pushParams))\n                (pushParamsName pushParams)\n                hashes\n          )\n  let missingHashes = Set.fromList (encodeUtf8 <$> missingHashesList)\n  pathsAndHashes <- liftIO $\n    for paths $\n      \\path -> do\n        hash_ <- Store.getStorePathHash path\n        pure (hash_, path)\n  return $ map snd $ filter (\\(hash_, _path) -> Set.member hash_ missingHashes) pathsAndHashes\n\n-- TODO: move to a separate module specific to cli\n\n-- | Find auth token or signing key in the \'Config\' or environment variable\nfindPushSecret ::\n  Config.Config ->\n  -- | Cache name\n  Text ->\n  -- | Secret key or exception\n  IO PushSecret\nfindPushSecret config name = do\n  maybeSigningKeyEnv <- toS <<$>> lookupEnv "CACHIX_SIGNING_KEY"\n  maybeAuthToken <- Config.getAuthTokenMaybe config\n  let maybeSigningKeyConfig = Config.secretKey <$> head (getBinaryCache config)\n  case maybeSigningKeyEnv <|> maybeSigningKeyConfig of\n    Just signingKey -> escalateAs FatalError $ PushSigningKey (fromMaybe (Token "") maybeAuthToken) <$> parseSigningKeyLenient signingKey\n    Nothing -> case maybeAuthToken of\n      Just authToken -> return $ PushToken authToken\n      Nothing -> throwIO $ NoSigningKey msg\n  where\n    -- we reverse list of caches to prioritize keys added as last\n    getBinaryCache c =\n      reverse $\n        filter (\\bc -> Config.name bc == name) (Config.binaryCaches c)\n    msg :: Text\n    msg =\n      [iTrim|\nNeither auth token nor signing key are present.\n\nThey are looked up via $CACHIX_AUTH_TOKEN and $CACHIX_SIGNING_KEY,\nand if missing also looked up from ~/.config/cachix/cachix.dhall\n\nRead https://mycache.cachix.org for instructions how to push to your binary cache.\n    |]\n\nmapConcurrentlyBounded :: Traversable t => Int -> (a -> IO b) -> t a -> IO (t b)\nmapConcurrentlyBounded bound action items = do\n  qs <- QSem.newQSem bound\n  let wrapped x = bracket_ (QSem.waitQSem qs) (QSem.signalQSem qs) (action x)\n  mapConcurrently wrapped items\n\n-------------------\n-- Private terms --\nsplitStorePath :: Text -> (Text, Text)\nsplitStorePath storePath =\n  (T.take 32 (T.drop 11 storePath), T.drop 44 storePath)\n'