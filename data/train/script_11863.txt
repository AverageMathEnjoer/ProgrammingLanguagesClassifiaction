b'/*\n    SPDX-FileCopyrightText: 2015-2020 Milian Wolff <mail@milianw.de>\n\n    SPDX-License-Identifier: LGPL-2.1-or-later\n*/\n\n#include "accumulatedtracedata.h"\n#include "analyze_config.h"\n\n#include <algorithm>\n#include <cassert>\n#include <iostream>\n#include <memory>\n\n#include <boost/algorithm/string/predicate.hpp>\n#include <boost/iostreams/filter/gzip.hpp>\n#if ZSTD_FOUND\n#if BOOST_IOSTREAMS_HAS_ZSTD\n#include <boost/iostreams/filter/zstd.hpp>\n#else\n#include <boost-zstd/zstd.hpp>\n#endif\n#endif\n#include <boost/iostreams/filtering_stream.hpp>\n\n#include <boost/filesystem.hpp>\n\n#include "util/config.h"\n#include "util/linereader.h"\n#include "util/pointermap.h"\n\n#include "suppressions.h"\n\n#ifdef __GNUC__\n#define POTENTIALLY_UNUSED __attribute__((unused))\n#else\n#define POTENTIALLY_UNUSED\n#endif\n\nusing namespace std;\n\nnamespace {\n\ntemplate <typename Base>\nbool operator>>(LineReader& reader, Index<Base>& index)\n{\n    return reader.readHex(index.index);\n}\n\ntemplate <typename Base>\nostream& operator<<(ostream& out, const Index<Base> index)\n{\n    out << index.index;\n    return out;\n}\n\n// boost\'s counter filter uses an int for the count which overflows for large streams; so replace it with a work alike.\nclass byte_counter\n{\npublic:\n    using char_type = char;\n    using category = boost::iostreams::multichar_input_filter_tag;\n\n    uint64_t bytes() const\n    {\n        return m_bytes;\n    }\n\n    template <typename Source>\n    std::streamsize read(Source& src, char* str, std::streamsize size)\n    {\n        auto const readsize = boost::iostreams::read(src, str, size);\n        if (readsize == -1)\n            return -1;\n        m_bytes += readsize;\n        return readsize;\n    }\n\nprivate:\n    uint64_t m_bytes = 0;\n};\n}\n\nAccumulatedTraceData::AccumulatedTraceData()\n{\n    instructionPointers.reserve(16384);\n    traces.reserve(65536);\n    strings.reserve(4096);\n    allocations.reserve(16384);\n    traceIndexToAllocationIndex.reserve(16384);\n    stopIndices.reserve(4);\n    opNewIpIndices.reserve(16);\n}\n\nAccumulatedTraceData::~AccumulatedTraceData() = default;\n\nconst string& AccumulatedTraceData::stringify(const StringIndex stringId) const\n{\n    if (!stringId || stringId.index > strings.size()) {\n        static const string empty;\n        return empty;\n    } else {\n        return strings.at(stringId.index - 1);\n    }\n}\n\nstring AccumulatedTraceData::prettyFunction(const string& function) const\n{\n    if (!shortenTemplates) {\n        return function;\n    }\n    string ret;\n    ret.reserve(function.size());\n    int depth = 0;\n    for (size_t i = 0; i < function.size(); ++i) {\n        const auto c = function[i];\n        if ((c == \'<\' || c == \'>\') && ret.size() >= 8) {\n            // don\'t get confused by C++ operators\n            const char* cmp = "operator";\n            if (ret.back() == c) {\n                // skip second angle bracket for operator<< or operator>>\n                if (c == \'<\') {\n                    cmp = "operator<";\n                } else {\n                    cmp = "operator>";\n                }\n            }\n            if (boost::algorithm::ends_with(ret, cmp)) {\n                ret.push_back(c);\n                continue;\n            }\n        }\n        if (c == \'<\') {\n            ++depth;\n            if (depth == 1) {\n                ret.push_back(c);\n            }\n        } else if (c == \'>\') {\n            --depth;\n        }\n        if (depth) {\n            continue;\n        }\n        ret.push_back(c);\n    }\n    return ret;\n}\n\nbool AccumulatedTraceData::read(const string& inputFile, bool isReparsing)\n{\n    return read(inputFile, FirstPass, isReparsing) && read(inputFile, SecondPass, isReparsing);\n}\n\nbool AccumulatedTraceData::read(const string& inputFile, const ParsePass pass, bool isReparsing)\n{\n    const bool isGzCompressed = boost::algorithm::ends_with(inputFile, ".gz");\n    const bool isZstdCompressed = boost::algorithm::ends_with(inputFile, ".zst");\n    const bool isCompressed = isGzCompressed || isZstdCompressed;\n    ifstream file(inputFile, isCompressed ? ios_base::in | ios_base::binary : ios_base::in);\n\n    if (!file.is_open()) {\n        cerr << "Failed to open heaptrack log file: " << inputFile << endl;\n        return false;\n    }\n\n    boost::iostreams::filtering_istream in;\n    in.push(byte_counter()); // caution, ::read dependant on filter order\n    if (isGzCompressed) {\n        in.push(boost::iostreams::gzip_decompressor());\n    } else if (isZstdCompressed) {\n#if ZSTD_FOUND\n        in.push(boost::iostreams::zstd_decompressor());\n#else\n        cerr << "Heaptrack was built without zstd support, cannot decompressed data file: " << inputFile << endl;\n        return false;\n#endif\n    }\n    in.push(byte_counter()); // caution, ::read dependant on filter order\n    in.push(file);\n\n    parsingState.fileSize = boost::filesystem::file_size(inputFile);\n\n    return read(in, pass, isReparsing);\n}\n\nbool AccumulatedTraceData::read(boost::iostreams::filtering_istream& in, const ParsePass pass, bool isReparsing)\n{\n    LineReader reader;\n    int64_t timeStamp = 0;\n\n    vector<string> opNewStrings = {\n        // 64 bit\n        "operator new(unsigned long)",\n        "operator new[](unsigned long)",\n        // 32 bit\n        "operator new(unsigned int)",\n        "operator new[](unsigned int)",\n    };\n    vector<StringIndex> opNewStrIndices;\n    opNewStrIndices.reserve(opNewStrings.size());\n\n    vector<string> stopStrings = {"main", "__libc_start_main", "__static_initialization_and_destruction_0"};\n\n    const auto lastPeakCost = pass != FirstPass ? totalCost.peak : 0;\n    const auto lastPeakTime = pass != FirstPass ? peakTime : 0;\n\n    totalCost = {};\n    peakTime = 0;\n    if (pass == FirstPass) {\n        if (!filterParameters.disableBuiltinSuppressions) {\n            suppressions = builtinSuppressions();\n        }\n\n        suppressions.resize(suppressions.size() + filterParameters.suppressions.size());\n        std::transform(filterParameters.suppressions.begin(), filterParameters.suppressions.end(), suppressions.begin(),\n                       [](const std::string& pattern) {\n                           return Suppression {pattern, 0, 0};\n                       });\n    }\n    peakRSS = 0;\n    for (auto& allocation : allocations) {\n        allocation.clearCost();\n    }\n    unsigned int fileVersion = 0;\n    bool debuggeeEncountered = false;\n    bool inFilteredTime = !filterParameters.minTime;\n\n    // required for backwards compatibility\n    // newer versions handle this in heaptrack_interpret already\n    AllocationInfoSet allocationInfoSet;\n    PointerMap pointers;\n    // in older files, this contains the pointer address, in newer formats\n    // it holds the allocation info index. both can be used to find temporary\n    // allocations, i.e. when a deallocation follows with the same data\n    uint64_t lastAllocationPtr = 0;\n\n    const auto uncompressedCount = in.component<byte_counter>(0);\n    const auto compressedCount = in.component<byte_counter>(in.size() - 2);\n\n    parsingState.pass = pass;\n    parsingState.reparsing = isReparsing;\n\n    while (timeStamp < filterParameters.maxTime && reader.getLine(in)) {\n        parsingState.readCompressedByte = compressedCount->bytes();\n        parsingState.readUncompressedByte = uncompressedCount->bytes();\n        parsingState.timestamp = timeStamp;\n\n        if (reader.mode() == \'s\') {\n            if (pass != FirstPass || isReparsing) {\n                continue;\n            }\n            if (fileVersion >= 3) {\n                // read sized string directly\n                std::string string;\n                reader >> string;\n                strings.push_back(std::move(string));\n            } else {\n                // read remaining line as string, possibly including white spaces\n                strings.push_back(reader.line().substr(2));\n            }\n\n            StringIndex index;\n            index.index = strings.size();\n\n            auto opNewIt = find(opNewStrings.begin(), opNewStrings.end(), strings.back());\n            if (opNewIt != opNewStrings.end()) {\n                opNewStrIndices.push_back(index);\n                opNewStrings.erase(opNewIt);\n            } else {\n                auto stopIt = find(stopStrings.begin(), stopStrings.end(), strings.back());\n                if (stopIt != stopStrings.end()) {\n                    stopIndices.push_back(index);\n                    stopStrings.erase(stopIt);\n                }\n            }\n        } else if (reader.mode() == \'t\') {\n            if (pass != FirstPass || isReparsing) {\n                continue;\n            }\n            TraceNode node;\n            reader >> node.ipIndex;\n            reader >> node.parentIndex;\n            // skip operator new and operator new[] at the beginning of traces\n            while (find(opNewIpIndices.begin(), opNewIpIndices.end(), node.ipIndex) != opNewIpIndices.end()) {\n                node = findTrace(node.parentIndex);\n            }\n            traces.push_back(node);\n        } else if (reader.mode() == \'i\') {\n            if (pass != FirstPass || isReparsing) {\n                continue;\n            }\n            InstructionPointer ip;\n            reader >> ip.instructionPointer;\n            reader >> ip.moduleIndex;\n            auto readFrame = [&reader](Frame* frame) {\n                return (reader >> frame->functionIndex) && (reader >> frame->fileIndex) && (reader >> frame->line);\n            };\n            if (readFrame(&ip.frame)) {\n                Frame inlinedFrame;\n                while (readFrame(&inlinedFrame)) {\n                    ip.inlined.push_back(inlinedFrame);\n                }\n            }\n\n            instructionPointers.push_back(ip);\n            if (find(opNewStrIndices.begin(), opNewStrIndices.end(), ip.frame.functionIndex) != opNewStrIndices.end()) {\n                IpIndex index;\n                index.index = instructionPointers.size();\n                opNewIpIndices.push_back(index);\n            }\n        } else if (reader.mode() == \'+\') {\n            if (!inFilteredTime) {\n                continue;\n            }\n            AllocationInfo info;\n            AllocationInfoIndex allocationIndex;\n            if (fileVersion >= 1) {\n                if (!(reader >> allocationIndex)) {\n                    cerr << "failed to parse line: " << reader.line() << \' \' << __LINE__ << endl;\n                    continue;\n                } else if (allocationIndex.index >= allocationInfos.size()) {\n                    cerr << "allocation index out of bounds: " << allocationIndex\n                         << ", maximum is: " << allocationInfos.size() << endl;\n                    continue;\n                }\n                info = allocationInfos[allocationIndex.index];\n                lastAllocationPtr = allocationIndex.index;\n            } else { // backwards compatibility\n                uint64_t ptr = 0;\n                TraceIndex traceIndex;\n                if (!(reader >> info.size) || !(reader >> traceIndex) || !(reader >> ptr)) {\n                    cerr << "failed to parse line: " << reader.line() << \' \' << __LINE__ << endl;\n                    continue;\n                }\n                info.allocationIndex = mapToAllocationIndex(traceIndex);\n                if (allocationInfoSet.add(info.size, traceIndex, &allocationIndex)) {\n                    allocationInfos.push_back(info);\n                }\n                pointers.addPointer(ptr, allocationIndex);\n                lastAllocationPtr = ptr;\n            }\n\n            if (pass != FirstPass) {\n                auto& allocation = allocations[info.allocationIndex.index];\n                allocation.leaked += info.size;\n                ++allocation.allocations;\n\n                handleAllocation(info, allocationIndex);\n            }\n\n            ++totalCost.allocations;\n            totalCost.leaked += info.size;\n            if (totalCost.leaked > totalCost.peak) {\n                totalCost.peak = totalCost.leaked;\n                peakTime = timeStamp;\n\n                if (pass == SecondPass && totalCost.peak == lastPeakCost && peakTime == lastPeakTime) {\n                    for (auto& allocation : allocations) {\n                        allocation.peak = allocation.leaked;\n                    }\n                }\n            }\n        } else if (reader.mode() == \'-\') {\n            if (!inFilteredTime) {\n                continue;\n            }\n            AllocationInfoIndex allocationInfoIndex;\n            bool temporary = false;\n            if (fileVersion >= 1) {\n                if (!(reader >> allocationInfoIndex)) {\n                    cerr << "failed to parse line: " << reader.line() << endl;\n                    continue;\n                }\n                temporary = lastAllocationPtr == allocationInfoIndex.index;\n            } else { // backwards compatibility\n                uint64_t ptr = 0;\n                if (!(reader >> ptr)) {\n                    cerr << "failed to parse line: " << reader.line() << endl;\n                    continue;\n                }\n                auto taken = pointers.takePointer(ptr);\n                if (!taken.second) {\n                    // happens when we attached to a running application\n                    continue;\n                }\n                allocationInfoIndex = taken.first;\n                temporary = lastAllocationPtr == ptr;\n            }\n            lastAllocationPtr = 0;\n\n            const auto& info = allocationInfos[allocationInfoIndex.index];\n            totalCost.leaked -= info.size;\n            if (temporary) {\n                ++totalCost.temporary;\n            }\n\n            if (pass != FirstPass) {\n                auto& allocation = allocations[info.allocationIndex.index];\n                allocation.leaked -= info.size;\n                if (temporary) {\n                    ++allocation.temporary;\n                }\n            }\n        } else if (reader.mode() == \'a\') {\n            if (pass != FirstPass || isReparsing) {\n                continue;\n            }\n            AllocationInfo info;\n            TraceIndex traceIndex;\n            if (!(reader >> info.size) || !(reader >> traceIndex)) {\n                cerr << "failed to parse line: " << reader.line() << endl;\n                continue;\n            }\n            info.allocationIndex = mapToAllocationIndex(traceIndex);\n            allocationInfos.push_back(info);\n\n        } else if (reader.mode() == \'#\') {\n            // comment or empty line\n            continue;\n        } else if (reader.mode() == \'c\') {\n            int64_t newStamp = 0;\n            if (!(reader >> newStamp)) {\n                cerr << "Failed to read time stamp: " << reader.line() << endl;\n                continue;\n            }\n            inFilteredTime = newStamp >= filterParameters.minTime && newStamp <= filterParameters.maxTime;\n            if (inFilteredTime) {\n                handleTimeStamp(timeStamp, newStamp, false, pass);\n            }\n            timeStamp = newStamp;\n        } else if (reader.mode() == \'R\') { // RSS timestamp\n            if (!inFilteredTime) {\n                continue;\n            }\n            int64_t rss = 0;\n            reader >> rss;\n            if (rss > peakRSS) {\n                peakRSS = rss;\n            }\n        } else if (reader.mode() == \'X\') {\n            if (debuggeeEncountered) {\n                cerr << "Duplicated debuggee entry - corrupt data file?" << endl;\n                return false;\n            }\n            debuggeeEncountered = true;\n            if (pass != FirstPass && !isReparsing) {\n                handleDebuggee(reader.line().c_str() + 2);\n            }\n        } else if (reader.mode() == \'A\') {\n            if (pass != FirstPass || isReparsing)\n                continue;\n            totalCost = {};\n            fromAttached = true;\n        } else if (reader.mode() == \'v\') {\n            unsigned int heaptrackVersion = 0;\n            reader >> heaptrackVersion;\n            if (!(reader >> fileVersion) && heaptrackVersion == 0x010200) {\n                // backwards compatibility: before the 1.0.0, I actually\n                // bumped the version to 0x010200 already and used that\n                // as file version. This is what we now consider v1 of the\n                // file format\n                fileVersion = 1;\n            }\n            if (fileVersion > HEAPTRACK_FILE_FORMAT_VERSION) {\n                cerr << "The data file has version " << hex << fileVersion << " and was written by heaptrack version "\n                     << hex << heaptrackVersion << ")\\n"\n                     << "This is not compatible with this build of heaptrack (version " << hex << HEAPTRACK_VERSION\n                     << "), which can read file format version " << hex << HEAPTRACK_FILE_FORMAT_VERSION << " and below"\n                     << endl;\n                return false;\n            }\n            if (fileVersion >= 3) {\n                reader.setExpectedSizedStrings(true);\n            }\n        } else if (reader.mode() == \'I\') { // system information\n            reader >> systemInfo.pageSize;\n            reader >> systemInfo.pages;\n        } else if (reader.mode() == \'S\') { // embedded suppression\n            if (pass != FirstPass || filterParameters.disableEmbeddedSuppressions) {\n                continue;\n            }\n            auto suppression = parseSuppression(reader.line().substr(2));\n            if (!suppression.empty()) {\n                suppressions.push_back({std::move(suppression), 0, 0});\n            }\n        } else {\n            cerr << "failed to parse line: " << reader.line() << endl;\n        }\n    }\n\n    if (pass == FirstPass && !isReparsing) {\n        totalTime = timeStamp + 1;\n        filterParameters.maxTime = totalTime;\n    }\n\n    handleTimeStamp(timeStamp, timeStamp + 1, true, pass);\n\n    return true;\n}\n\nnamespace { // helpers for diffing\n\ntemplate <typename IndexT, typename SortF>\nvector<IndexT> sortedIndices(size_t numIndices, SortF sorter)\n{\n    vector<IndexT> indices;\n    indices.resize(numIndices);\n    for (size_t i = 0; i < numIndices; ++i) {\n        indices[i].index = (i + 1);\n    }\n    sort(indices.begin(), indices.end(), sorter);\n    return indices;\n}\n\nvector<StringIndex> remapStrings(vector<string>& lhs, const vector<string>& rhs)\n{\n    tsl::robin_map<string, StringIndex> stringRemapping;\n\n    // insert known strings in lhs into the map for lookup below\n    StringIndex stringIndex;\n    {\n        stringRemapping.reserve(lhs.size());\n        for (const auto& string : lhs) {\n            ++stringIndex.index;\n            stringRemapping.insert(make_pair(string, stringIndex));\n        }\n    }\n\n    // now insert the missing strings form rhs into lhs\n    // and create a remapped string vector, keeping the order\n    // of the strings in rhs, but mapping into the string vector from lhs\n    vector<StringIndex> map;\n    {\n        map.reserve(rhs.size() + 1);\n        map.push_back({});\n        for (const auto& string : rhs) {\n            auto it = stringRemapping.find(string);\n            if (it == stringRemapping.end()) {\n                // a string that only occurs in rhs, but not lhs\n                // add it to lhs to make sure we can find it again later on\n                ++stringIndex.index;\n                lhs.push_back(string);\n                map.push_back(stringIndex);\n            } else {\n                map.push_back(it->second);\n            }\n        }\n    }\n    return map;\n}\n\n// replace by std::identity once we can leverage C++20\nstruct identity\n{\n    template <typename T>\n    const T& operator()(const T& t) const\n    {\n        return t;\n    }\n\n    template <typename T>\n    T operator()(T&& t) const\n    {\n        return std::move(t);\n    }\n};\n\ntemplate <typename IpMapper>\nint compareTraceIndices(const TraceIndex& lhs, const AccumulatedTraceData& lhsData, const TraceIndex& rhs,\n                        const AccumulatedTraceData& rhsData, IpMapper ipMapper)\n{\n    if (!lhs && !rhs) {\n        return 0;\n    } else if (lhs && !rhs) {\n        return 1;\n    } else if (rhs && !lhs) {\n        return -1;\n    } else if (&lhsData == &rhsData && lhs == rhs) {\n        // fast-path if both indices are equal and we compare the same data\n        return 0;\n    }\n\n    const auto& lhsTrace = lhsData.findTrace(lhs);\n    const auto& rhsTrace = rhsData.findTrace(rhs);\n\n    const int parentComparsion =\n        compareTraceIndices(lhsTrace.parentIndex, lhsData, rhsTrace.parentIndex, rhsData, ipMapper);\n    if (parentComparsion != 0) {\n        return parentComparsion;\n    } // else fall-through to below, parents are equal\n\n    const auto& lhsIp = lhsData.findIp(lhsTrace.ipIndex);\n    const auto& rhsIp = ipMapper(rhsData.findIp(rhsTrace.ipIndex));\n    if (lhsIp.equalWithoutAddress(rhsIp)) {\n        return 0;\n    }\n    return lhsIp.compareWithoutAddress(rhsIp) ? -1 : 1;\n}\n\nPOTENTIALLY_UNUSED void printCost(const AllocationData& data)\n{\n    cerr << data.allocations << " (" << data.temporary << "), " << data.peak << " (" << data.leaked << ")\\n";\n}\n\nPOTENTIALLY_UNUSED void printTrace(const AccumulatedTraceData& data, TraceIndex index)\n{\n    do {\n        const auto trace = data.findTrace(index);\n        const auto& ip = data.findIp(trace.ipIndex);\n        cerr << index << " (" << trace.ipIndex << ", " << trace.parentIndex << ")" << \'\\t\'\n             << data.stringify(ip.frame.functionIndex) << " in " << data.stringify(ip.moduleIndex) << " at "\n             << data.stringify(ip.frame.fileIndex) << \':\' << ip.frame.line << \'\\n\';\n        for (const auto& inlined : ip.inlined) {\n            cerr << \'\\t\' << data.stringify(inlined.functionIndex) << " at " << data.stringify(inlined.fileIndex) << \':\'\n                 << inlined.line << \'\\n\';\n        }\n        index = trace.parentIndex;\n    } while (index);\n    cerr << "---\\n";\n}\n\ntemplate <class ForwardIt, class BinaryPredicateCompare, class BinaryOpReduce>\nForwardIt inplace_unique_reduce(ForwardIt first, ForwardIt last, BinaryPredicateCompare cmp, BinaryOpReduce reduce)\n{\n    if (first == last)\n        return last;\n\n    ForwardIt result = first;\n    while (++first != last) {\n        if (cmp(*result, *first)) {\n            reduce(*result, *first);\n        } else if (++result != first) {\n            *result = std::move(*first);\n        }\n    }\n    return ++result;\n}\n}\n\nvoid AccumulatedTraceData::diff(const AccumulatedTraceData& base)\n{\n    totalCost -= base.totalCost;\n    totalTime -= base.totalTime;\n    peakRSS -= base.peakRSS;\n    systemInfo.pages -= base.systemInfo.pages;\n    systemInfo.pageSize -= base.systemInfo.pageSize;\n\n    // step 1: sort allocations for efficient lookup and to prepare for merging equal allocations\n\n    std::sort(allocations.begin(), allocations.end(), [this](const Allocation& lhs, const Allocation& rhs) {\n        return compareTraceIndices(lhs.traceIndex, *this, rhs.traceIndex, *this, identity {}) < 0;\n    });\n\n    // step 2: now merge equal allocations\n\n    allocations.erase(inplace_unique_reduce(\n                          allocations.begin(), allocations.end(),\n                          [this](const Allocation& lhs, const Allocation& rhs) {\n                              return compareTraceIndices(lhs.traceIndex, *this, rhs.traceIndex, *this, identity {})\n                                  == 0;\n                          },\n                          [](Allocation& lhs, const Allocation& rhs) { lhs += rhs; }),\n                      allocations.end());\n\n    // step 3: map string indices from rhs to lhs data\n\n    const auto& stringMap = remapStrings(strings, base.strings);\n    auto remapString = [&stringMap](StringIndex& index) {\n        if (index) {\n            index.index = stringMap[index.index].index;\n        }\n    };\n    auto remapFrame = [&remapString](Frame frame) -> Frame {\n        remapString(frame.functionIndex);\n        remapString(frame.fileIndex);\n        return frame;\n    };\n    auto remapIp = [&remapString, &remapFrame](InstructionPointer ip) -> InstructionPointer {\n        remapString(ip.moduleIndex);\n        ip.frame = remapFrame(ip.frame);\n        for (auto& inlined : ip.inlined) {\n            inlined = remapFrame(inlined);\n        }\n        return ip;\n    };\n\n    // step 4: iterate over rhs data and find matching traces\n    //         if no match is found, copy the data over\n\n    auto sortedIps = sortedIndices<IpIndex>(instructionPointers.size(), [this](const IpIndex& lhs, const IpIndex& rhs) {\n        return findIp(lhs).compareWithoutAddress(findIp(rhs));\n    });\n\n    // map an IpIndex from the rhs data into the lhs data space, or copy the data\n    // if it does not exist yet\n    auto remapIpIndex = [&sortedIps, this, &base, &remapIp](IpIndex rhsIndex) -> IpIndex {\n        if (!rhsIndex) {\n            return rhsIndex;\n        }\n\n        const auto& rhsIp = base.findIp(rhsIndex);\n        const auto& lhsIp = remapIp(rhsIp);\n\n        auto it = lower_bound(sortedIps.begin(), sortedIps.end(), lhsIp,\n                              [this](const IpIndex& lhs, const InstructionPointer& rhs) {\n                                  return findIp(lhs).compareWithoutAddress(rhs);\n                              });\n        if (it != sortedIps.end() && findIp(*it).equalWithoutAddress(lhsIp)) {\n            return *it;\n        }\n\n        instructionPointers.push_back(lhsIp);\n\n        IpIndex ret;\n        ret.index = instructionPointers.size();\n        sortedIps.insert(it, ret);\n\n        return ret;\n    };\n\n    // copy the rhs trace index and the data it references into the lhs data,\n    // recursively\n    function<TraceIndex(TraceIndex)> copyTrace = [this, &base, remapIpIndex,\n                                                  &copyTrace](TraceIndex rhsIndex) -> TraceIndex {\n        if (!rhsIndex) {\n            return rhsIndex;\n        }\n\n        // new location, add it\n        const auto& rhsTrace = base.findTrace(rhsIndex);\n\n        TraceNode node;\n        node.parentIndex = copyTrace(rhsTrace.parentIndex);\n        node.ipIndex = remapIpIndex(rhsTrace.ipIndex);\n\n        traces.push_back(node);\n        TraceIndex ret;\n        ret.index = traces.size();\n\n        return ret;\n    };\n\n    // find an equivalent trace or copy the data over if it does not exist yet\n    // a trace is equivalent if the complete backtrace has equal InstructionPointer\n    // data while ignoring the actual pointer address\n    for (const auto& rhsAllocation : base.allocations) {\n\n        assert(rhsAllocation.traceIndex);\n        auto it = lower_bound(allocations.begin(), allocations.end(), rhsAllocation.traceIndex,\n                              [&base, this, remapIp](const Allocation& lhs, const TraceIndex& rhs) -> bool {\n                                  return compareTraceIndices(lhs.traceIndex, *this, rhs, base, remapIp) < 0;\n                              });\n\n        if (it == allocations.end()\n            || compareTraceIndices(it->traceIndex, *this, rhsAllocation.traceIndex, base, remapIp) != 0) {\n            Allocation lhsAllocation;\n            lhsAllocation.traceIndex = copyTrace(rhsAllocation.traceIndex);\n            it = allocations.insert(it, lhsAllocation);\n        }\n\n        (*it) -= rhsAllocation;\n    }\n\n    // step 5: remove allocations that don\'t show any differences\n    //         note that when there are differences in the backtraces,\n    //         we can still end up with merged backtraces that have a total\n    //         of 0, but different "tails" of different origin with non-zero cost\n    allocations.erase(remove_if(allocations.begin(), allocations.end(),\n                                [&](const Allocation& allocation) -> bool { return allocation == AllocationData(); }),\n                      allocations.end());\n}\n\nAllocationIndex AccumulatedTraceData::mapToAllocationIndex(const TraceIndex traceIndex)\n{\n    AllocationIndex allocationIndex;\n    if (traceIndex < m_maxAllocationTraceIndex) {\n        // only need to search when the trace index is previously known\n        auto it = lower_bound(traceIndexToAllocationIndex.begin(), traceIndexToAllocationIndex.end(), traceIndex,\n                              [](const pair<TraceIndex, AllocationIndex>& indexMap,\n                                 const TraceIndex traceIndex) -> bool { return indexMap.first < traceIndex; });\n        if (it != traceIndexToAllocationIndex.end() && it->first == traceIndex) {\n            return it->second;\n        }\n        // new allocation\n        allocationIndex.index = allocations.size();\n        traceIndexToAllocationIndex.insert(it, make_pair(traceIndex, allocationIndex));\n        Allocation allocation;\n        allocation.traceIndex = traceIndex;\n        allocations.push_back(allocation);\n    } else if (traceIndex == m_maxAllocationTraceIndex && !allocations.empty()) {\n        // reuse the last allocation\n        assert(allocations[m_maxAllocationIndex.index].traceIndex == traceIndex);\n        allocationIndex = m_maxAllocationIndex;\n    } else {\n        // new allocation\n        allocationIndex.index = allocations.size();\n        traceIndexToAllocationIndex.push_back(make_pair(traceIndex, allocationIndex));\n        Allocation allocation;\n        allocation.traceIndex = traceIndex;\n        m_maxAllocationIndex.index = allocations.size();\n        allocations.push_back(allocation);\n        m_maxAllocationTraceIndex = traceIndex;\n    }\n    return allocationIndex;\n}\n\nconst InstructionPointer& AccumulatedTraceData::findIp(const IpIndex ipIndex) const\n{\n    static const InstructionPointer invalid;\n    if (!ipIndex || ipIndex.index > instructionPointers.size()) {\n        return invalid;\n    } else {\n        return instructionPointers[ipIndex.index - 1];\n    }\n}\n\nTraceNode AccumulatedTraceData::findTrace(const TraceIndex traceIndex) const\n{\n    if (!traceIndex || traceIndex.index > traces.size()) {\n        return {};\n    } else {\n        return traces[traceIndex.index - 1];\n    }\n}\n\nbool AccumulatedTraceData::isStopIndex(const StringIndex index) const\n{\n    return find(stopIndices.begin(), stopIndices.end(), index) != stopIndices.end();\n}\n\nstruct SuppressionStringMatch\n{\n    static constexpr auto NO_MATCH = std::numeric_limits<std::size_t>::max();\n\n    SuppressionStringMatch(std::size_t index = NO_MATCH)\n        : suppressionIndex(index)\n    {\n    }\n\n    explicit operator bool() const\n    {\n        return suppressionIndex != NO_MATCH;\n    }\n\n    std::size_t suppressionIndex;\n};\n\nvoid AccumulatedTraceData::applyLeakSuppressions()\n{\n    totalLeakedSuppressed = 0;\n\n    if (suppressions.empty()) {\n        return;\n    }\n\n    // match all strings once against all suppression rules\n    bool hasAnyMatch = false;\n    std::vector<SuppressionStringMatch> suppressedStrings(strings.size());\n    std::transform(strings.begin(), strings.end(), suppressedStrings.begin(), [&](const auto& string) {\n        auto it = std::find_if(suppressions.begin(), suppressions.end(), [&string](const Suppression& suppression) {\n            return matchesSuppression(suppression.pattern, string);\n        });\n        if (it == suppressions.end()) {\n            return SuppressionStringMatch();\n        } else {\n            hasAnyMatch = true;\n            return SuppressionStringMatch(static_cast<std::size_t>(std::distance(suppressions.begin(), it)));\n        }\n    });\n    if (!hasAnyMatch) {\n        // nothing matched the suppressions, we can return early\n        return;\n    }\n\n    auto isSuppressedString = [&suppressedStrings](StringIndex index) {\n        if (index && index.index <= suppressedStrings.size()) {\n            return suppressedStrings[index.index - 1];\n        } else {\n            return SuppressionStringMatch();\n        }\n    };\n    auto isSuppressedFrame = [&isSuppressedString](Frame frame) {\n        auto match = isSuppressedString(frame.functionIndex);\n        if (match) {\n            return match;\n        }\n        return isSuppressedString(frame.fileIndex);\n    };\n\n    // now match all instruction pointers against the suppressed strings\n    std::vector<SuppressionStringMatch> suppressedIps(instructionPointers.size());\n    std::transform(instructionPointers.begin(), instructionPointers.end(), suppressedIps.begin(), [&](const auto& ip) {\n        auto match = isSuppressedString(ip.moduleIndex);\n        if (match) {\n            return match;\n        }\n        match = isSuppressedFrame(ip.frame);\n        if (match) {\n            return match;\n        }\n        for (const auto& inlined : ip.inlined) {\n            match = isSuppressedFrame(inlined);\n            if (match) {\n                return match;\n            }\n        }\n        return SuppressionStringMatch();\n    });\n    suppressedStrings = {};\n    auto isSuppressedIp = [&suppressedIps](IpIndex index) {\n        if (index && index.index <= suppressedIps.size()) {\n            return suppressedIps[index.index - 1];\n        }\n        return SuppressionStringMatch();\n    };\n\n    // now match all trace indices against the suppressed instruction pointers\n    std::vector<SuppressionStringMatch> suppressedTraces(traces.size());\n    auto isSuppressedTrace = [&suppressedTraces](TraceIndex index) {\n        if (index && index.index <= suppressedTraces.size()) {\n            return suppressedTraces[index.index - 1];\n        }\n        return SuppressionStringMatch();\n    };\n    std::transform(traces.begin(), traces.end(), suppressedTraces.begin(), [&](const auto& trace) {\n        auto match = isSuppressedTrace(trace.parentIndex);\n        if (match) {\n            return match;\n        }\n        return isSuppressedIp(trace.ipIndex);\n    });\n    suppressedIps = {};\n\n    // now finally zero all the matching allocations\n    for (auto& allocation : allocations) {\n        auto match = isSuppressedTrace(allocation.traceIndex);\n        if (match) {\n            totalLeakedSuppressed += allocation.leaked;\n\n            auto& suppression = suppressions[match.suppressionIndex];\n            ++suppression.matches;\n            suppression.leaked += allocation.leaked;\n\n            totalCost.leaked -= allocation.leaked;\n            allocation.leaked = 0;\n        }\n    }\n}\n'