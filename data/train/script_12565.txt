b'# helper function used by FSR() and getPoly()\n\n# converts each df column in cols to factor, returns new df\n# for getPoly(), and by extension polyFit() and FSR():\n# should be used on any categorical variable stored as an integer\n# is optional for binary variables\n# is optional for categorical variables stored as characters\n#\' @export\ntoFactors <- function(df, cols)\n{  \n  for (i in cols) {\n    df[,i] <- as.factor(df[,i])\n  }\n  df\n}\n\n# the rest are not exported...\n\nN_distinct <- function(x) \n{\n   if(ncol(as.matrix(x)) == 1) length(unique(x)) \n   else unlist(lapply(x, N_distinct))\n}\n\n#is_continuous <- function(x) if(is.numeric(x)) N_distict(x) > 2 else FALSE\nis_continuous <- function(x) \n   unlist(lapply(x, is.numeric)) & N_distinct(x) > 2\n\nmod <- function(m) paste0("model", m)\n\nmatch_arg <- \n   function(arg, choices){if(is.null(arg)) arg else match.arg(arg, choices)}\n\ncomplete_vector <- function(x) !is.null(x) && sum(is.na(x)) == 0\n\ncomplete <- function(xy, noisy=TRUE){\n  n_row <- nrow(xy)\n  # xy <- xy[complete.cases(xy),,drop=FALSE]\n  xy <- na.exclude(xy)\n  if (is.vector(xy)) xy <- matrix(xy,ncol=1)\n  n_raw <- nrow(xy)\n  # xy <- xy[complete.cases(xy),,drop=FALSE]\n  xy <- na.exclude(xy)\n  n <- nrow(xy)\n  return(xy)\n}\n\n\nmodel_matrix <- function(modelFormula, dataFrame, intercept, noisy=TRUE, ...){\n\n    tried <- try(model.matrix(modelFormula, dataFrame, na.action = "na.omit", ...), silent=TRUE)\n    \n    if(inherits(tried, "try-error")){\n      \n      if(noisy) warning("model.matrix() reported the following error:\\n", tried, "\\n\\n")\n      return(NULL)\n      \n    } else {\n      if(intercept) return(tried) else return(tried[,-1,drop=FALSE])\n    }\n  \n}\n\nget_degree <- function(combo){\n\n  if(grepl("\\\\^", combo)){\n\n    ch <- unlist(strsplit(combo, "^"))\n    start <- match("^", ch) + 1\n    end <- match(")", ch) - 1\n    return(as.numeric(paste(ch[start:end], collapse="")))\n\n  }else{\n    return(1)\n  }\n}\n\nget_interactions <- function(features, maxInteractDeg, \n                             may_not_repeat = NULL, maxDeg = NULL, \n                             include_features = TRUE){\n  \n  if(length(features) < maxInteractDeg)\n    stop("too few x variables to obtain desired interaction degree.")\n\n  # interactions will initially be an R list, one element per\n  # interaction degree\n  interactions <- list()\n\n  if(length(features) > 1 && maxInteractDeg > 1){\n    for(i in 2:maxInteractDeg){\n\n      combos <- combn(features, i) # i x choose(n, i) matrix\n      combos <- combos[ , which_include(combos, may_not_repeat)]\n\n      if(!is.null(maxDeg)) # drop combos for which sum of degrees > maxDeg\n        combos <- \n           combos[,-which(colSums(apply(combos, 1:2, get_degree)) > maxDeg)]\n\n      interactions[[i]] <- apply(as.matrix(combos), 2, paste, collapse = " * ")\n\n    }\n  }\n  interactions <- unlist(interactions)\n\n  if(include_features) \n     return(c(features, interactions)) else return(interactions)\n\n}\n\ngtInteractions <- get_interactions\n\nwhich_include <- function(combos, may_not_repeat){\n# prevents multiplication of mutually exclusive categorical variables\' levels\n# suppose you have a factor variable, party with levels D, R, I\n# at this point, factor features are strings formatted\n# (party == \'D\') and (party == \'R\')\n# but identical((party == \'D\') * (party == \'R\'), rep(0, N)) == TRUE\n# this function uses grepl() to prevent such 0 columns from entering\n# the formula subsequently...\n#\n# also, different monomials of the same variable should not interact\n# raising the polynomial degree beyond user specification\n\n  combos <- as.matrix(combos)\n\n  keepers <- 1:ncol(combos)\n\n  if(length(may_not_repeat) == 0){\n\n    return(keepers)\n\n  }else{\n\n    to_drop <- list()\n\n    for(i in 1:length(may_not_repeat)){\n      to_drop[[i]] <- which(colSums(apply(combos, 2, grepl, pattern = may_not_repeat[i])) > 1)\n    }\n    to_drop <- unique(unlist(to_drop))\n\n    if(length(to_drop)) return(keepers[-to_drop]) else return(keepers)\n  }\n}\n\n# depracated\nisolate_interaction <- function(elements, degree){\n\n  f <- paste(elements, collapse = " * ")\n  for(i in 1:degree){\n    tmp <- combn(elements, i)\n    if(i > 1)\n      tmp <- apply(tmp, 2, paste, collapse="*")\n    f <- paste(f, "-", paste(tmp, collapse=" - "))\n  }\n  return(f)\n\n}\n\nclassify <- function(probs, as_factor=TRUE, labels=NULL, cutoff = NULL){ # not meant for binary labels...\n\n  if(ncol(as.matrix(probs)) == 1){\n\n    if(is.null(labels))\n      labels <- c("label1", "label2")\n\n    if(is.null(cutoff))\n      cutoff <- 0.5\n\n    classified <- labels[(probs > cutoff) + 1]\n\n  }else{\n\n    if(!is.null(labels))\n      colnames(probs) <- labels\n    if(is.null(colnames(probs)))\n      colnames(probs) <- paste0("label", 1:ncol(probs))\n    classified <- colnames(probs)[apply(probs, 1, which.max)]\n\n  }\n\n  if(as_factor)\n    classified <- as.factor(classified)\n\n  return(classified)\n\n}\n\n\nlog_odds <- function(x, split = NULL, noisy = TRUE){\n\n  if(N_distinct(x) == 2){\n\n    if(is.factor(x))\n      x <- as.numeric(x) - 1\n    p <- mean(if(is.null(split)) x else x[split], na.rm=TRUE)\n    y <- ifelse(x == 1, log(p/(1 - p)), log((1 - p)/p))\n\n  }else{\n\n    if(!is.factor(x))\n      x <- as.factor(x)\n\n    if(is.null(split)){\n\n      p_reference <- mean(x == levels(x)[1])\n      y <- matrix(nrow = length(x), ncol = (length(levels(x)) - 1))\n      colnames(y) <- levels(x)[-1]\n      for(i in 1:ncol(y)){\n        p_interest <- mean(x == levels(x)[i + 1])\n        y[ , i] <- ifelse(x == levels(x)[i + 1],\n                          log(p_interest/p_reference),\n                          log(p_reference/p_interest))\n      }\n\n    }else{ # put whole sample on training scale, so N rows, not N_train\n\n      x_train <- x[split]\n      p_reference <- mean(x_train == levels(x)[1])\n      y <- matrix(nrow = length(x),\n                  ncol = (length(levels(x_train)) - 1))\n      colnames(y) <- levels(x_train)[-1]\n      for(i in 1:ncol(y)){\n        p_interest <- mean(x_train == levels(x_train)[i + 1])\n        y[ , i] <- ifelse(x == levels(x_train)[i + 1],\n                          log(p_interest/p_reference),\n                          log(p_reference/p_interest))\n      }\n    }\n  }\n\n  if(noisy && sum(is.na(y)))\n    warning("NAs encountered by log_odds")\n\n  return(y)\n\n}\n# if !recursive, divides into blocks based on n and max_block\n# if recursive, calls block_solve(), rather than solve(), until n/2 < max_block\n# note: matrix inversion and several matrix multiplications must be performed on largest blocks!\n# assumes matrices are dense; otherwise, use sparse options...\n# max_block chosen by trial-and-error on 2017 MacBook Pro i5 with 16 gigs of RAM\n# (too small == too much subsetting, too big == matrix calculations too taxing)\n#  S, crossprod(X), will be crossprod(X) only at outer call\n# Either S or X should be provided, but not both\n# S = | A B |\n#     | C D |\n# for full expressions used below: https://en.wikipedia.org/wiki/Invertible_matrix#Blockwise_inversion\n# returns NULL if inversion fails either due to collinearity or memory exhaustion\n\nblock_solve  <- function(S = NULL, X = NULL, max_block = 250, A_inv = NULL, recursive=TRUE, noisy=TRUE){\n\n  if(is.null(S) == is.null(X))\n    stop("Please provide either rectangular matrix as X or a square matrix as S to be inverted by block_solve(). (If X is provided, (X\'X)^{-1} is returned but in a more memory efficient manner than providing S = X\'X directly).")\n\n  if(!is.null(A_inv) && is.null(X))\n    stop("If A_inv is provided, X must be provided to block_solve() too. (Suppose A_inv has p columns; A must be equal to solve(crossprod(X[,1:p])) or, equivalently, block_solve(X=X[,1:p]).")\n\n  solvable <- function(A, noisy=TRUE){\n\n    tried <- try(solve(A), silent = noisy)\n    if(noisy) cat(".") # optional progress bar... better than message() or warning()\n                       # controlled by user input in FSR()\n    if(inherits(tried, "try-error")) return(NULL) else return(tried)\n\n  }\n\n  if(is.null(X)){\n\n    stopifnot(nrow(S) == ncol(S))\n\n    symmetric <- isSymmetric(S)\n    n <- ncol(S)   # if S is crossprod(X), this is really a p * p matrix\n    k <- floor(n/2)\n\n    A <- S[1:k, 1:k]\n    B <- S[1:k, (k + 1):n]\n    D <- S[(k + 1):n, (k + 1):n]\n\n  }else{\n\n    n <- ncol(X)     # n refers to the resulting crossproduct of S as above\n    if(is.null(A_inv)){\n      k <- floor(n/2)\n      A <- crossprod(X[,1:k])\n    }else{\n      k <- ncol(A_inv)\n    }\n    B <- crossprod(X[,1:k], X[,(k+1):n])\n    D <- crossprod(X[,(k+1):n])\n\n    symmetric <- TRUE   # refers to S, not A, B, or D (B in general will be rectangular...)\n\n  }\n\n  invert <- if(recursive && (k > max_block)) block_solve else solvable\n\n  if(is.null(A_inv)){\n    A_inv <- invert(A, noisy=noisy)\n    remove(A)\n  }\n\n  if(!is.null(A_inv)){\n\n\n    if(symmetric){\n      # S, crossprod(X), will be symmetric at highest level but not at lower levels\n      # want memory savings from that symmetry when it applies\n      # by symmetry, B == t(C), so C is never constructed\n      if(exists("S")) remove(S)\n      C.A_inv <- crossprod(B, A_inv) # really C %*% A_inv since C == t(B)\n      schur_inv <- invert(D - C.A_inv %*% B)\n      remove(D)\n\n      if(!is.null(schur_inv)){\n\n        S_inv <- matrix(nrow=n, ncol=n)\n\n        S_inv[1:k, 1:k] <- A_inv + A_inv %*% B %*% schur_inv %*% C.A_inv\n        remove(B, A_inv)\n        S_inv[(k+1):n, 1:k] <- -schur_inv %*% C.A_inv\n        S_inv[(k+1):n, (k+1):n] <- schur_inv\n        remove(schur_inv, C.A_inv)\n        S_inv[1:k, (k+1):n] <- t(S_inv[(k+1):n, 1:k]) # since symmetric matrices have symm inverses\n        return(S_inv)\n\n      }else{\n        return(NULL)\n      }\n\n    }else{\n\n      C.A_inv <- crossprod(B, A_inv) # S[(k+1):n, 1:k] %*% A_inv  # really C %*% A_inv\n\n      if(exists("C.A_inv")){\n\n        if(exists("S")) remove(S)\n\n        schur_inv <- invert(D - C.A_inv %*% B, noisy=noisy)\n        remove(D)\n\n        S_inv <- matrix(nrow=n, ncol=n)\n        S_inv[1:k, 1:k] <- A_inv + A_inv %*% B %*% schur_inv %*% C.A_inv\n        S_inv[(k+1):n, 1:k] <- -schur_inv %*% C.A_inv\n        remove(C.A_inv)\n        S_inv[(k+1):n, (k+1):n] <- schur_inv\n        S_inv[1:k, (k+1):n] <- -A_inv %*% B %*% schur_inv\n        remove(B, A_inv, schur_inv)\n        return(S_inv)\n\n      }else{\n        return(NULL)\n      }\n    }\n  }else{\n    return(NULL)\n  }\n\n}\n\n\n\nols <- function(object, Xy, m, train = TRUE, y = NULL, y_test = NULL){\n\n  X <- if(train){\n          model_matrix(formula(object$models$formula[m]),\n                        Xy[object$split == "train", ],\n                        noisy = object$noisy, intercept=TRUE)\n       }else{\n          model_matrix(formula(object$models$formula[m]),\n                        Xy, noisy = object$noisy, intercept=TRUE)\n       }\n\n  if(exists("X")){\n\n    if(is.null(y))\n      y <- if(train) Xy[object$split == "train", ncol(Xy)] else Xy[, ncol(Xy)]\n\n    if(ncol(X) >= length(y) && object$noisy){\n\n      message("There are too few training observations to estimate further models (model == ",\n              m, "). Exiting.")\n      object$unable_to_estimate <- object$max_fails\n\n    }else{\n\n      XtX_inv <- block_solve(X = X, max_block = object$max_block,\n                             A_inv = object$XtX_inv_accepted)\n                                    # initialized to NULL,\n                                    # which block_solve interprets as \'start from scratch\'\n\n      if(!is.null(XtX_inv)){\n\n        object[[mod(m)]][["coeffs"]] <- tcrossprod(XtX_inv, X) %*% y\n\n        if(complete_vector(object[[mod(m)]][["coeffs"]])){\n\n          object$models$estimated[m] <- TRUE\n\n          object <- post_estimation(object, Xy, m, y_test)\n          if(object$models$accepted[m])\n            object$XtX_inv_accepted <- XtX_inv\n\n          remove(XtX_inv)\n\n        }\n      }\n    }\n  }\n  if(!object$models$estimated[m]){\n    warning("Unable to estimate model", m, "\\n\\n")\n    object$unable_to_estimate <- object$unable_to_estimate + 1\n  }\n  if(object$noisy) message("\\n")\n  return(object)\n}\n\npost_estimation <- function(object, Xy, m, y_test = NULL){\n\n    P <- if(object$outcome == "multinomial")\n            nrow(object[[mod(m)]][["coeffs"]]) else length(object[[mod(m)]][["coeffs"]])\n\n    object$models$P[m] <- object[[mod(m)]][["p"]]  <- P\n\n    if(is.null(y_test))\n      y_test <- Xy[object$split == "test", ncol(Xy)]\n\n    if(object$outcome == "continuous"){\n\n      object[[mod(m)]][["y_hat"]] <- predict(object, Xy[object$split=="test", ], m, standardize = FALSE)\n      MAPE <- object$y_scale * mean(abs(object[[mod(m)]][["y_hat"]] - y_test))\n      object$models$MAPE[m] <- object[[mod(m)]][["MAPE"]] <- MAPE\n\n    }else{\n\n      pred <- predict(object, Xy[object$split=="test", ], m, standardize = FALSE)\n\n      object[[mod(m)]][["y_hat"]] <- pred$probs\n      object[[mod(m)]][["classified"]] <- pred$classified\n\n      object$models$test_accuracy[m] <- mean(as.character(pred$classified) == object$y_test_labels)\n\n      if(!object$linear_estimation){\n\n        object$models$AIC[m] <- if(object$outcome == "binary")\n                                    object[[mod(m)]][["fit"]][["aic"]] else\n                                      object[[mod(m)]][["fit"]][["AIC"]]\n\n        object$models$BIC[m] <- object$models$AIC[m] - 2*P + log(object$N_train)*P\n\n      }\n    }\n\n    if(object$outcome != "multinomial"){\n\n      R2 <- cor(object[[mod(m)]][["y_hat"]], as.numeric(y_test))^2\n\n      adjR2 <- (object$N_train - P - 1)/(object$N_train - 1)*R2\n\n      object$models$test_adjR2[m] <- object[[mod(m)]][["adj_R2"]] <- adjR2\n\n      improvement <- adjR2 - object$best_test_adjR2\n\n    }else{\n\n      adj_accuracy <- (object$N_train - P)/(object$N_train - 1)*object$models$test_accuracy[m]\n\n      object$models$test_adj_accuracy[m] <- adj_accuracy\n\n      improvement <- adj_accuracy - object$best_test_adj_accuracy\n\n    }\n\n    object[["improvement"]] <- improvement\n\n  if(object$improvement > object$threshold_include){\n\n      object[["best_formula"]] <- object$models$formula[m]\n      object[["best_coeffs"]] <- object[[mod(m)]][["coeffs"]]\n\n      if(object$outcome == "multinomial"){\n        object[["best_test_adj_accuracy"]] <- adj_accuracy\n      }else{\n        object[["best_test_adjR2"]] <- adjR2\n      }\n\n      object$models$accepted[m] <- TRUE\n\n      if(object$outcome == "continuous"){\n        object[[\'best_adjR2\']] <- adjR2 \n        object[["best_MAPE"]] <- MAPE\n      }\n  }\n  return(object)\n}\n\n\n\n'