b'# WEEK 3 SOLUTIONS\n\nlibrary(rethinking)\ndata(foxes)\nd <- foxes\nd$W <- standardize(d$weight)\nd$A <- standardize(d$area)\nd$F <- standardize(d$avgfood)\nd$G <- standardize(d$groupsize)\n\n# 1 \n\nm1 <- quap(\n    alist(\n        F ~ dnorm( mu , sigma ),\n        mu <- a + bA*A,\n        a ~ dnorm(0,0.2),\n        bA ~ dnorm(0,0.5),\n        sigma ~ dexp(1)\n    ), data=d )\n\n# 2\n\n# total effect\n\nm2 <- quap(\n    alist(\n        W ~ dnorm( mu , sigma ),\n        mu <- a + bF*F,\n        a ~ dnorm(0,0.2),\n        bF ~ dnorm(0,0.5),\n        sigma ~ dexp(1)\n    ), data=d )\n\n# direct effect of F\n\nm2b <- quap(\n    alist(\n        W ~ dnorm( mu , sigma ),\n        mu <- a + bF*F + bG*G,\n        a ~ dnorm(0,0.2),\n        c(bF,bG) ~ dnorm(0,0.5),\n        sigma ~ dexp(1)\n    ), data=d )\n\n# direct effect of F on G\n\nm2c <- quap(\n    alist(\n        G ~ dnorm( mu , sigma ),\n        mu <- a + bF*F,\n        a ~ dnorm(0,0.2),\n        bF ~ dnorm(0,0.5),\n        sigma ~ dexp(1)\n    ), data=d )\n\n# 3\n\n\nlibrary(dagitty)\nt2f_dag <- dagitty( "dag {\n    X -> Y\n    S -> X\n    S -> Y\n    A -> Y\n    A -> X\n    A -> S\n    S <- U -> Y\n}")\nadjustmentSets( t2f_dag , exposure="X" , outcome="Y" )\n\n\n# 4\n# Writeasyntheticdatasimulationforthecausal model shown in Problem 3. Be sure to include the unobserved confound in the simulation. Choose any functional relationships that you like\xe2\x80\x94you don\xe2\x80\x99t have to get the epidemiology correct. You just need to honor the causal structure. Then design a regression model to estimate the influence of X on Y and use it on your synthetic data. How large of a sample do you need to reliably estimate P(Y|do(X))? Define \xe2\x80\x9creliably\xe2\x80\x9d as you like, but justify your definition.\n\nf <- function(N=100,bX=0) {\n    U <- rnorm(N)\n    A <- rnorm(N)\n    S <- rnorm(N,A+U)\n    X <- rnorm(N,A+S)\n    Y <- rnorm(N,A+S+bX*X+U)\n    return(list(\n        A=standardize(A),\n        S=standardize(S),\n        X=standardize(X),\n        Y=standardize(Y)))\n}\n\nflist <- alist(\n        Y ~ dnorm(mu,exp(log_sigma)),\n        mu <- a + bX*X + bS*S + bA*A,\n        a ~ dnorm(0,0.2),\n        c(bX,bS,bA) ~ dnorm(0,0.5),\n        log_sigma ~ dnorm(0,1)\n    )\n\nsim_dat <- f(N=10,bX=0)\nm4 <- quap( flist , data=sim_dat )\nprecis(m4)\n\n# function to repeat analysis at specific N\ng <- function(N_reps=1e3,N=100,bX=0) {\n    r <- mcreplicate( N_reps , mc.cores=8 , {\n        sim_dat <- f(N=N,bX=bX)\n        m <- quap( flist , data=sim_dat )\n        # return width of 89% interval and mean distance from true value\n        iw <- as.numeric( precis(m)[2,4] - precis(m)[2,3] )\n        md <- as.numeric( abs(precis(m)[2,1] - 0) )\n        return(c(md,iw))\n    } )\n    return(r)\n}\n\nx <- g(N=10)\n\nplot( x[2,] , lwd=2 , col=4 , ylim=c(0,max(x)) , xlab="simulation" , ylab="value" )\npoints( 1:ncol(x) , x[1,] , lwd=2 , col=2 )\n\nabline( h=mean(x[1,]) , lwd=6 , col="white" )\nabline( h=mean(x[1,]) , lwd=3 , col=2 )\n\nabline( h=mean(x[2,]) , lwd=6 , col="white" )\nabline( h=mean(x[2,]) , lwd=3 , col=4 )\n\n# now plot mean bias and precision across values of N\nN_seq <- c(10,20,50,100,500,1000)\n\ny <- sapply( N_seq , function(n) {\n    x <- g(N=n)\n    return( c( apply(x,1,mean) , apply(x,1,sd) ) ) \n} )\n\nplot( N_seq , y[2,] , lwd=3 , col=4 , type="b" , ylim=c(0,1) , xlab="N" , ylab="value" )\npoints( N_seq , y[1,] , lwd=3 , col=2 , type="b" )\nfor ( i in 1:length(N_seq) ) {\n    lines( c(N_seq[i],N_seq[i]) , c(y[1,i]+y[3,i],y[1,i]-y[3,i]) , lwd=3 , col=2 )\n    lines( c(N_seq[i],N_seq[i]) , c(y[2,i]+y[4,i],y[2,i]-y[4,i]) , lwd=3 , col=4 )\n}\n'